{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distributional word representations (Exercise 2 + Homework 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much of this taken from Christopher Potts' CS224u course from Spring 2016."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "__author1__ = \"Nishant Subramani\" (TA)\n",
    "__author2__ = \"Isha Chaturvedi\" (Student)\n",
    "__version__ = \"DSGA 1012, NYU, Spring 2018 term\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents\n",
    "\n",
    "0. [Overview](#Overview)\n",
    "0. [Set-up](#Set-up)\n",
    "0. [Distributional matrices](#Distributional-matrices)\n",
    "0. [Vector comparison](#Vector-comparison)\n",
    "    0. [Euclidean distance](#Euclidean-distance)\n",
    "    0. [Length normalization](#Length-normalization)\n",
    "    0. [Cosine distance](#Cosine-distance)\n",
    "    0. [Summary](#Summary)\n",
    "0. [Distributional neighbors](#Distributional-neighbors)    \n",
    "0. [Matrix reweighting](#Matrix-reweighting)\n",
    "    0. [Normalization](#Normalization)\n",
    "    0. [Pointwise Mutual Information](#Pointwise-Mutual-Information)\n",
    "0. [Dimensionality reduction](#Dimensionality-reduction)\n",
    "0. [Word analogies evaluation](#Word-analogies-evaluation)\n",
    "0. [Homework 1](#Homework-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "In this exercise and assignment, we want to explore creating vector representations of words (__distributional representations__) from co-occurence patterns in text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set-up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, install matplotlib using conda. The command below should work. \n",
    "\n",
    "Note: If any of the below imports fail, you have to conda install them as well. Google conda install package-name and you will find a command to run."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Run this on terminal: conda install -c conda-forge matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Make sure your environment includes all the requirements for [the cs224u repository](https://github.com/cgpotts/cs224u).\n",
    "* Download [the data distribution for this unit](https://web.stanford.edu/class/cs224u/data/vsmdata.zip), unpack it, and place it in the directory containing the course repository. (If you want to put it somewhere else, change `vsmdata_home` below.)\n",
    "* Download [the Wikipedia 2014 + Gigaword 5 distribution](http://nlp.stanford.edu/data/glove.6B.zip) of the pretrained GloVe vectors, unzip it, and put the resulting folder in the the same directory as this notebook. (If you want to put it somewhere else, change `glove_home` below.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "vsmdata_home = \"vsmdata\"\n",
    "glove_home = \"glove.6B\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import csv\n",
    "import random\n",
    "import itertools\n",
    "from operator import itemgetter\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "#import scipy\n",
    "#import scipy.spatial.distance\n",
    "from numpy.linalg import svd\n",
    "import matplotlib.pyplot as plt\n",
    "#from sklearn.decomposition import PCA\n",
    "#from sklearn.manifold import TSNE\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import math.log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distributional matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a basic recipe for building a word $\\times$ word matrix:\n",
    "    \n",
    "0. Define a notion of co-occurrence context. This could be an entire document, a paragraph, a sentence, a clause, an NP â€” whatever domain seems likely to capture the associations you care about.\n",
    "0. Scan through your corpus building a dictionary $d$ mapping word-pairs to counts. Every time a pair of words $w$ and $w'$ occurs in the same context (as you defined it in 1),  increment $d[(w, w')]$ by $1$.\n",
    "0. Using the count dictionary $d$ that you collected in 2, establish your full vocabulary $V$, an ordered list of words types. For large collections of documents, $|V|$ will typically be huge. You will probably want to winnow the vocabulary at this point. You might do this by filtering to a specific subset, or just imposing a minimum count threshold. You might impose a minimum count threshold even if $|V|$ is small &mdash; for words with very low counts, you simply don't have enough evidence to say anything interesting.\n",
    "0. Now build a matrix $M$ of dimension $|V| \\times |V|$. Both the rows and the columns of $M$ represent words. Each cell $M[i, j]$ is filled with the count $d[(w_i, w_j)]$.\n",
    "\n",
    "For different designs, the procedure differs slightly. For example, if you are building a word $\\times$ document matrix, then the rows of $M$ represent words and the columns of $M$ represent documents. The scan in step 2 then just keeps track of (_word_, _document_) pairs &mdash; compiling the number of times that _word_ appears in _document_. Such matrices are often used in information retrieval, because the columns are multi-set representations of documents. They are much sparser than the the word $\\times$ word matrices we will work with here. (In my experience, they yield lower-quality lexicons, but others have reported good results with them.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data distribution includes two pre-computed matrices of co-occurrence counts in IMDB movie reviews. The `build` function in the `utils` module for this repository  allows you to read them in:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's read these in now for use in later examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ww = utils.build(os.path.join(vsmdata_home, 'imdb-wordword.csv'))\n",
    "wd = utils.build(os.path.join(vsmdata_home, 'imdb-worddoc.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[  3.43744000e+05,   2.25000000e+02,   4.41000000e+02, ...,\n",
       "           4.74000000e+02,   1.62500000e+03,   1.05000000e+03],\n",
       "        [  1.43000000e+02,   2.18000000e+02,   9.00000000e+00, ...,\n",
       "           3.00000000e+00,   3.00000000e+00,   5.00000000e+00],\n",
       "        [  2.91000000e+02,   5.00000000e+00,   4.72000000e+02, ...,\n",
       "           8.00000000e+00,   1.00000000e+01,   5.00000000e+00],\n",
       "        ..., \n",
       "        [  2.80000000e+01,   3.00000000e+00,   8.00000000e+00, ...,\n",
       "           2.58000000e+02,   2.10000000e+01,   8.00000000e+00],\n",
       "        [  1.05300000e+03,   3.00000000e+00,   3.00000000e+00, ...,\n",
       "           1.40000000e+01,   3.36100000e+03,   1.42800000e+03],\n",
       "        [  5.16000000e+02,   1.00000000e+00,   2.00000000e+00, ...,\n",
       "           3.00000000e+00,   9.89000000e+02,   1.25000000e+03]]),\n",
       " ['!',\n",
       "  '):',\n",
       "  ');',\n",
       "  '1',\n",
       "  '1/10',\n",
       "  '1/2',\n",
       "  '10',\n",
       "  '10/10',\n",
       "  '100',\n",
       "  '11',\n",
       "  '12',\n",
       "  '13',\n",
       "  '14',\n",
       "  '15',\n",
       "  '17',\n",
       "  '1950',\n",
       "  '1950s',\n",
       "  '1970',\n",
       "  '1980',\n",
       "  '2',\n",
       "  '20',\n",
       "  '2000',\n",
       "  '25',\n",
       "  '3',\n",
       "  '3/10',\n",
       "  '30',\n",
       "  '4',\n",
       "  '4/10',\n",
       "  '40',\n",
       "  '5',\n",
       "  '50',\n",
       "  '6',\n",
       "  '60',\n",
       "  '60s',\n",
       "  '7',\n",
       "  '7/10',\n",
       "  '70',\n",
       "  '70s',\n",
       "  '8',\n",
       "  '8/',\n",
       "  '80',\n",
       "  '80s',\n",
       "  '9',\n",
       "  '90',\n",
       "  ':)',\n",
       "  '?',\n",
       "  'a',\n",
       "  'abandoned',\n",
       "  'ability',\n",
       "  'able',\n",
       "  'about',\n",
       "  'above',\n",
       "  'absolute',\n",
       "  'absolutely',\n",
       "  'absurd',\n",
       "  'abuse',\n",
       "  'academy',\n",
       "  'accent',\n",
       "  'accents',\n",
       "  'accept',\n",
       "  'accident',\n",
       "  'accidentally',\n",
       "  'according',\n",
       "  'account',\n",
       "  'accurate',\n",
       "  'achieve',\n",
       "  'across',\n",
       "  'act',\n",
       "  'acted',\n",
       "  'acting',\n",
       "  'action',\n",
       "  'actions',\n",
       "  'actor',\n",
       "  'actors',\n",
       "  'actress',\n",
       "  'actresses',\n",
       "  'acts',\n",
       "  'actual',\n",
       "  'actually',\n",
       "  'adam',\n",
       "  'adaptation',\n",
       "  'add',\n",
       "  'added',\n",
       "  'adding',\n",
       "  'addition',\n",
       "  'adds',\n",
       "  'admit',\n",
       "  'adult',\n",
       "  'adults',\n",
       "  'adventure',\n",
       "  'adventures',\n",
       "  'advice',\n",
       "  'affair',\n",
       "  'afraid',\n",
       "  'africa',\n",
       "  'african',\n",
       "  'after',\n",
       "  'afternoon',\n",
       "  'again',\n",
       "  'against',\n",
       "  'age',\n",
       "  'agent',\n",
       "  'ages',\n",
       "  'ago',\n",
       "  'agree',\n",
       "  'ahead',\n",
       "  \"ain't\",\n",
       "  'air',\n",
       "  'aka',\n",
       "  'al',\n",
       "  'alan',\n",
       "  'alas',\n",
       "  'albert',\n",
       "  'alex',\n",
       "  'alice',\n",
       "  'alien',\n",
       "  'aliens',\n",
       "  'alive',\n",
       "  'all',\n",
       "  'allen',\n",
       "  'allow',\n",
       "  'allowed',\n",
       "  'allows',\n",
       "  'almost',\n",
       "  'alone',\n",
       "  'along',\n",
       "  'already',\n",
       "  'alright',\n",
       "  'also',\n",
       "  'although',\n",
       "  'always',\n",
       "  'am',\n",
       "  'amateur',\n",
       "  'amateurish',\n",
       "  'amazed',\n",
       "  'amazing',\n",
       "  'amazingly',\n",
       "  'america',\n",
       "  'american',\n",
       "  'americans',\n",
       "  'among',\n",
       "  'amongst',\n",
       "  'amount',\n",
       "  'amusing',\n",
       "  'an',\n",
       "  'ancient',\n",
       "  'and',\n",
       "  'anderson',\n",
       "  'andy',\n",
       "  'angel',\n",
       "  'angels',\n",
       "  'anger',\n",
       "  'angle',\n",
       "  'angles',\n",
       "  'angry',\n",
       "  'animal',\n",
       "  'animals',\n",
       "  'animated',\n",
       "  'animation',\n",
       "  'anime',\n",
       "  'ann',\n",
       "  'anna',\n",
       "  'anne',\n",
       "  'annoying',\n",
       "  'another',\n",
       "  'answer',\n",
       "  'answers',\n",
       "  'anthony',\n",
       "  'any',\n",
       "  'anybody',\n",
       "  'anymore',\n",
       "  'anyone',\n",
       "  'anything',\n",
       "  'anyway',\n",
       "  'anywhere',\n",
       "  'apart',\n",
       "  'apartment',\n",
       "  'apparent',\n",
       "  'apparently',\n",
       "  'appeal',\n",
       "  'appealing',\n",
       "  'appear',\n",
       "  'appearance',\n",
       "  'appeared',\n",
       "  'appears',\n",
       "  'appreciate',\n",
       "  'appreciated',\n",
       "  'approach',\n",
       "  'appropriate',\n",
       "  'are',\n",
       "  'area',\n",
       "  \"aren't\",\n",
       "  'arms',\n",
       "  'army',\n",
       "  'around',\n",
       "  'arrives',\n",
       "  'art',\n",
       "  'arthur',\n",
       "  'artist',\n",
       "  'artistic',\n",
       "  'artists',\n",
       "  'arts',\n",
       "  'as',\n",
       "  'ashamed',\n",
       "  'asian',\n",
       "  'aside',\n",
       "  'ask',\n",
       "  'asked',\n",
       "  'asking',\n",
       "  'asks',\n",
       "  'asleep',\n",
       "  'aspect',\n",
       "  'aspects',\n",
       "  'ass',\n",
       "  'assume',\n",
       "  'at',\n",
       "  'atmosphere',\n",
       "  'atrocious',\n",
       "  'attack',\n",
       "  'attacked',\n",
       "  'attacks',\n",
       "  'attempt',\n",
       "  'attempting',\n",
       "  'attempts',\n",
       "  'attention',\n",
       "  'attitude',\n",
       "  'attractive',\n",
       "  'audience',\n",
       "  'audiences',\n",
       "  'aunt',\n",
       "  'australian',\n",
       "  'authentic',\n",
       "  'author',\n",
       "  'available',\n",
       "  'average',\n",
       "  'avoid',\n",
       "  'award',\n",
       "  'awards',\n",
       "  'aware',\n",
       "  'away',\n",
       "  'awesome',\n",
       "  'awful',\n",
       "  'awkward',\n",
       "  'b',\n",
       "  'b-movie',\n",
       "  'baby',\n",
       "  'back',\n",
       "  'background',\n",
       "  'bad',\n",
       "  'badly',\n",
       "  'balance',\n",
       "  'ball',\n",
       "  'band',\n",
       "  'bank',\n",
       "  'bar',\n",
       "  'barbara',\n",
       "  'barely',\n",
       "  'base',\n",
       "  'baseball',\n",
       "  'based',\n",
       "  'basic',\n",
       "  'basically',\n",
       "  'basis',\n",
       "  'batman',\n",
       "  'battle',\n",
       "  'bbc',\n",
       "  'be',\n",
       "  'beach',\n",
       "  'bear',\n",
       "  'beast',\n",
       "  'beat',\n",
       "  'beautiful',\n",
       "  'beautifully',\n",
       "  'beauty',\n",
       "  'became',\n",
       "  'because',\n",
       "  'become',\n",
       "  'becomes',\n",
       "  'becoming',\n",
       "  'bed',\n",
       "  'been',\n",
       "  'before',\n",
       "  'began',\n",
       "  'begin',\n",
       "  'beginning',\n",
       "  'begins',\n",
       "  'behavior',\n",
       "  'behind',\n",
       "  'being',\n",
       "  'belief',\n",
       "  'believable',\n",
       "  'believe',\n",
       "  'believed',\n",
       "  'believes',\n",
       "  'beloved',\n",
       "  'below',\n",
       "  'ben',\n",
       "  'besides',\n",
       "  'best',\n",
       "  'bet',\n",
       "  'better',\n",
       "  'between',\n",
       "  'beyond',\n",
       "  'big',\n",
       "  'bigger',\n",
       "  'biggest',\n",
       "  'bill',\n",
       "  'billy',\n",
       "  'birth',\n",
       "  'bit',\n",
       "  'bits',\n",
       "  'bizarre',\n",
       "  'black',\n",
       "  'blah',\n",
       "  'blair',\n",
       "  'blame',\n",
       "  'bland',\n",
       "  'blind',\n",
       "  'blockbuster',\n",
       "  'blonde',\n",
       "  'blood',\n",
       "  'bloody',\n",
       "  'blow',\n",
       "  'blown',\n",
       "  'blue',\n",
       "  'board',\n",
       "  'boat',\n",
       "  'bob',\n",
       "  'bodies',\n",
       "  'body',\n",
       "  'bollywood',\n",
       "  'bomb',\n",
       "  'bond',\n",
       "  'book',\n",
       "  'books',\n",
       "  'bore',\n",
       "  'bored',\n",
       "  'boring',\n",
       "  'born',\n",
       "  'boss',\n",
       "  'both',\n",
       "  'bother',\n",
       "  'bothered',\n",
       "  'bottom',\n",
       "  'bought',\n",
       "  'bourne',\n",
       "  'box',\n",
       "  'boy',\n",
       "  'boyfriend',\n",
       "  'boys',\n",
       "  'brad',\n",
       "  'brain',\n",
       "  'brave',\n",
       "  'break',\n",
       "  'breaking',\n",
       "  'breaks',\n",
       "  'breath',\n",
       "  'breathtaking',\n",
       "  'brian',\n",
       "  'brief',\n",
       "  'bright',\n",
       "  'brilliant',\n",
       "  'brilliantly',\n",
       "  'bring',\n",
       "  'bringing',\n",
       "  'brings',\n",
       "  'british',\n",
       "  'broadway',\n",
       "  'broken',\n",
       "  'brooks',\n",
       "  'brother',\n",
       "  'brothers',\n",
       "  'brought',\n",
       "  'brown',\n",
       "  'bruce',\n",
       "  'brutal',\n",
       "  'buddy',\n",
       "  'budget',\n",
       "  'build',\n",
       "  'building',\n",
       "  'built',\n",
       "  'bunch',\n",
       "  'burns',\n",
       "  'burt',\n",
       "  'bus',\n",
       "  'business',\n",
       "  'busy',\n",
       "  'but',\n",
       "  'buy',\n",
       "  'buying',\n",
       "  'by',\n",
       "  'c',\n",
       "  'cabin',\n",
       "  'cable',\n",
       "  'cage',\n",
       "  'caine',\n",
       "  'california',\n",
       "  'call',\n",
       "  'called',\n",
       "  'calling',\n",
       "  'calls',\n",
       "  'came',\n",
       "  'cameo',\n",
       "  'camera',\n",
       "  'camp',\n",
       "  'campy',\n",
       "  'can',\n",
       "  \"can't\",\n",
       "  'canadian',\n",
       "  'candy',\n",
       "  'cannot',\n",
       "  'cant',\n",
       "  'capable',\n",
       "  'captain',\n",
       "  'capture',\n",
       "  'captured',\n",
       "  'captures',\n",
       "  'car',\n",
       "  'care',\n",
       "  'career',\n",
       "  'cares',\n",
       "  'caring',\n",
       "  'carried',\n",
       "  'carries',\n",
       "  'carry',\n",
       "  'carrying',\n",
       "  'cars',\n",
       "  'cartoon',\n",
       "  'cartoons',\n",
       "  'case',\n",
       "  'cases',\n",
       "  'cash',\n",
       "  'cast',\n",
       "  'casting',\n",
       "  'castle',\n",
       "  'cat',\n",
       "  'catch',\n",
       "  'category',\n",
       "  'caught',\n",
       "  'cause',\n",
       "  'caused',\n",
       "  'causes',\n",
       "  'cell',\n",
       "  'center',\n",
       "  'central',\n",
       "  'century',\n",
       "  'certain',\n",
       "  'certainly',\n",
       "  'cgi',\n",
       "  'challenge',\n",
       "  'chance',\n",
       "  'change',\n",
       "  'changed',\n",
       "  'changes',\n",
       "  'changing',\n",
       "  'channel',\n",
       "  'character',\n",
       "  \"character's\",\n",
       "  'characters',\n",
       "  'charge',\n",
       "  'charles',\n",
       "  'charlie',\n",
       "  'charm',\n",
       "  'charming',\n",
       "  'chase',\n",
       "  'che',\n",
       "  'cheap',\n",
       "  'check',\n",
       "  'cheesy',\n",
       "  'chemistry',\n",
       "  'chick',\n",
       "  'chief',\n",
       "  'child',\n",
       "  'childhood',\n",
       "  'children',\n",
       "  \"children's\",\n",
       "  'chilling',\n",
       "  'china',\n",
       "  'chinese',\n",
       "  'choice',\n",
       "  'choices',\n",
       "  'choose',\n",
       "  'chose',\n",
       "  'chosen',\n",
       "  'chris',\n",
       "  'christian',\n",
       "  'christmas',\n",
       "  'christopher',\n",
       "  'church',\n",
       "  'cinderella',\n",
       "  'cinema',\n",
       "  'cinematic',\n",
       "  'cinematography',\n",
       "  'circumstances',\n",
       "  'city',\n",
       "  'claim',\n",
       "  'claims',\n",
       "  'claire',\n",
       "  'clark',\n",
       "  'class',\n",
       "  'classic',\n",
       "  'classics',\n",
       "  'clean',\n",
       "  'clear',\n",
       "  'clearly',\n",
       "  'clever',\n",
       "  'clich',\n",
       "  'climax',\n",
       "  'clips',\n",
       "  'close',\n",
       "  'closer',\n",
       "  'closing',\n",
       "  'clothes',\n",
       "  'club',\n",
       "  'clue',\n",
       "  'code',\n",
       "  'cold',\n",
       "  'collection',\n",
       "  'college',\n",
       "  'color',\n",
       "  'colors',\n",
       "  'columbo',\n",
       "  'combination',\n",
       "  'combined',\n",
       "  'come',\n",
       "  'comedic',\n",
       "  'comedies',\n",
       "  'comedy',\n",
       "  'comes',\n",
       "  'comic',\n",
       "  'comical',\n",
       "  'coming',\n",
       "  'comment',\n",
       "  'commentary',\n",
       "  'comments',\n",
       "  'commercial',\n",
       "  'committed',\n",
       "  'common',\n",
       "  'community',\n",
       "  'company',\n",
       "  'compare',\n",
       "  'compared',\n",
       "  'comparison',\n",
       "  'compelling',\n",
       "  'complete',\n",
       "  'completely',\n",
       "  'complex',\n",
       "  'complicated',\n",
       "  'computer',\n",
       "  'concept',\n",
       "  'concerned',\n",
       "  'conclusion',\n",
       "  'conflict',\n",
       "  'confused',\n",
       "  'confusing',\n",
       "  'confusion',\n",
       "  'connection',\n",
       "  'consider',\n",
       "  'considered',\n",
       "  'considering',\n",
       "  'constant',\n",
       "  'constantly',\n",
       "  'contain',\n",
       "  'contains',\n",
       "  'contemporary',\n",
       "  'content',\n",
       "  'context',\n",
       "  'continue',\n",
       "  'continues',\n",
       "  'continuity',\n",
       "  'contrast',\n",
       "  'contrived',\n",
       "  'control',\n",
       "  'conversation',\n",
       "  'convey',\n",
       "  'convince',\n",
       "  'convinced',\n",
       "  'convincing',\n",
       "  'cool',\n",
       "  'cop',\n",
       "  'cops',\n",
       "  'copy',\n",
       "  'core',\n",
       "  'corny',\n",
       "  'correct',\n",
       "  'cost',\n",
       "  'costs',\n",
       "  'costume',\n",
       "  'costumes',\n",
       "  'could',\n",
       "  \"could've\",\n",
       "  \"couldn't\",\n",
       "  'count',\n",
       "  'country',\n",
       "  'couple',\n",
       "  'course',\n",
       "  'court',\n",
       "  'cover',\n",
       "  'covered',\n",
       "  'cowboy',\n",
       "  'crap',\n",
       "  'crappy',\n",
       "  'crash',\n",
       "  'crazy',\n",
       "  'create',\n",
       "  'created',\n",
       "  'creates',\n",
       "  'creating',\n",
       "  'creative',\n",
       "  'creature',\n",
       "  'creatures',\n",
       "  'credit',\n",
       "  'credits',\n",
       "  'creepy',\n",
       "  'crew',\n",
       "  'crime',\n",
       "  'criminal',\n",
       "  'criminals',\n",
       "  'critical',\n",
       "  'criticism',\n",
       "  'critics',\n",
       "  'cross',\n",
       "  'crowd',\n",
       "  'crude',\n",
       "  'cruel',\n",
       "  'cry',\n",
       "  'crying',\n",
       "  'cult',\n",
       "  'cultural',\n",
       "  'culture',\n",
       "  'curious',\n",
       "  'current',\n",
       "  'cut',\n",
       "  'cute',\n",
       "  'cuts',\n",
       "  'cutting',\n",
       "  'd',\n",
       "  'dad',\n",
       "  'daily',\n",
       "  'damn',\n",
       "  'dan',\n",
       "  'dance',\n",
       "  'dancing',\n",
       "  'danger',\n",
       "  'dangerous',\n",
       "  'daniel',\n",
       "  'danny',\n",
       "  'dark',\n",
       "  'darkness',\n",
       "  'date',\n",
       "  'dated',\n",
       "  'daughter',\n",
       "  'daughters',\n",
       "  'david',\n",
       "  'davis',\n",
       "  'day',\n",
       "  'days',\n",
       "  'de',\n",
       "  'dead',\n",
       "  'deadly',\n",
       "  'deal',\n",
       "  'dealing',\n",
       "  'deals',\n",
       "  'dean',\n",
       "  'death',\n",
       "  'deaths',\n",
       "  'debut',\n",
       "  'decade',\n",
       "  'decades',\n",
       "  'decent',\n",
       "  'decide',\n",
       "  'decided',\n",
       "  'decides',\n",
       "  'decision',\n",
       "  'deep',\n",
       "  'deeper',\n",
       "  'deeply',\n",
       "  'definitely',\n",
       "  'degree',\n",
       "  'delight',\n",
       "  'delightful',\n",
       "  'deliver',\n",
       "  'delivered',\n",
       "  'delivers',\n",
       "  'delivery',\n",
       "  'demon',\n",
       "  'demons',\n",
       "  'dennis',\n",
       "  'department',\n",
       "  'depicted',\n",
       "  'depiction',\n",
       "  'depressing',\n",
       "  'depth',\n",
       "  'describe',\n",
       "  'described',\n",
       "  'description',\n",
       "  'desert',\n",
       "  'deserve',\n",
       "  'deserved',\n",
       "  'deserves',\n",
       "  'design',\n",
       "  'designed',\n",
       "  'desire',\n",
       "  'desperate',\n",
       "  'desperately',\n",
       "  'despite',\n",
       "  'destroy',\n",
       "  'destroyed',\n",
       "  'detail',\n",
       "  'details',\n",
       "  'detective',\n",
       "  'determined',\n",
       "  'develop',\n",
       "  'developed',\n",
       "  'development',\n",
       "  'device',\n",
       "  'devil',\n",
       "  'dialog',\n",
       "  'dialogue',\n",
       "  'dick',\n",
       "  'did',\n",
       "  \"didn't\",\n",
       "  'die',\n",
       "  'died',\n",
       "  'dies',\n",
       "  'difference',\n",
       "  'different',\n",
       "  'difficult',\n",
       "  'direct',\n",
       "  'directed',\n",
       "  'directing',\n",
       "  'direction',\n",
       "  'directly',\n",
       "  'director',\n",
       "  \"director's\",\n",
       "  'directors',\n",
       "  'dirty',\n",
       "  'disappointed',\n",
       "  'disappointing',\n",
       "  'disappointment',\n",
       "  'disaster',\n",
       "  'disbelief',\n",
       "  'discover',\n",
       "  'discovered',\n",
       "  'discovers',\n",
       "  'disgusting',\n",
       "  'disney',\n",
       "  'display',\n",
       "  'disturbing',\n",
       "  'do',\n",
       "  'doctor',\n",
       "  'documentary',\n",
       "  'does',\n",
       "  \"doesn't\",\n",
       "  'dog',\n",
       "  'dogs',\n",
       "  'doing',\n",
       "  'dollar',\n",
       "  'dollars',\n",
       "  'don',\n",
       "  \"don't\",\n",
       "  'donald',\n",
       "  'done',\n",
       "  'door',\n",
       "  'double',\n",
       "  'doubt',\n",
       "  'douglas',\n",
       "  'down',\n",
       "  'downright',\n",
       "  'dozen',\n",
       "  'dr',\n",
       "  'drag',\n",
       "  'dragon',\n",
       "  'drama',\n",
       "  'dramatic',\n",
       "  'draw',\n",
       "  'drawn',\n",
       "  'dreadful',\n",
       "  'dream',\n",
       "  'dreams',\n",
       "  'dress',\n",
       "  'dressed',\n",
       "  'drew',\n",
       "  'drinking',\n",
       "  'drive',\n",
       "  'driven',\n",
       "  'driver',\n",
       "  'driving',\n",
       "  'drop',\n",
       "  'drug',\n",
       "  'drugs',\n",
       "  'drunk',\n",
       "  'dry',\n",
       "  'dubbed',\n",
       "  'dude',\n",
       "  'due',\n",
       "  'dull',\n",
       "  'dumb',\n",
       "  'during',\n",
       "  'dvd',\n",
       "  'dying',\n",
       "  'e',\n",
       "  'each',\n",
       "  'earlier',\n",
       "  'early',\n",
       "  'earth',\n",
       "  'easily',\n",
       "  'easy',\n",
       "  'eat',\n",
       "  'eating',\n",
       "  'ed',\n",
       "  'eddie',\n",
       "  'edge',\n",
       "  'edited',\n",
       "  'editing',\n",
       "  'edward',\n",
       "  'effect',\n",
       "  'effective',\n",
       "  'effectively',\n",
       "  'effects',\n",
       "  'effort',\n",
       "  'efforts',\n",
       "  'eight',\n",
       "  'either',\n",
       "  'element',\n",
       "  'elements',\n",
       "  'elizabeth',\n",
       "  'else',\n",
       "  'embarrassed',\n",
       "  'embarrassing',\n",
       "  'emma',\n",
       "  'emotion',\n",
       "  'emotional',\n",
       "  'emotionally',\n",
       "  'emotions',\n",
       "  'empty',\n",
       "  'encounter',\n",
       "  'end',\n",
       "  'ended',\n",
       "  'ending',\n",
       "  'endless',\n",
       "  'ends',\n",
       "  'enemy',\n",
       "  'energy',\n",
       "  'engaging',\n",
       "  'england',\n",
       "  'english',\n",
       "  'enjoy',\n",
       "  'enjoyable',\n",
       "  'enjoyed',\n",
       "  'enjoying',\n",
       "  'enough',\n",
       "  'enter',\n",
       "  'entertain',\n",
       "  'entertained',\n",
       "  'entertaining',\n",
       "  'entertainment',\n",
       "  'entire',\n",
       "  'entirely',\n",
       "  'environment',\n",
       "  'epic',\n",
       "  'episode',\n",
       "  'episodes',\n",
       "  'equally',\n",
       "  'era',\n",
       "  'eric',\n",
       "  'erotic',\n",
       "  'escape',\n",
       "  'escapes',\n",
       "  'especially',\n",
       "  'essential',\n",
       "  'essentially',\n",
       "  'established',\n",
       "  'etc',\n",
       "  'europe',\n",
       "  'european',\n",
       "  'even',\n",
       "  'evening',\n",
       "  'event',\n",
       "  'events',\n",
       "  'eventually',\n",
       "  'ever',\n",
       "  'every',\n",
       "  'everybody',\n",
       "  'everyday',\n",
       "  'everyone',\n",
       "  'everything',\n",
       "  'everywhere',\n",
       "  'evidence',\n",
       "  'evil',\n",
       "  'exact',\n",
       "  'exactly',\n",
       "  'example',\n",
       "  'examples',\n",
       "  'excellent',\n",
       "  'except',\n",
       "  'exception',\n",
       "  'excited',\n",
       "  'excitement',\n",
       "  'exciting',\n",
       "  'excuse',\n",
       "  'executed',\n",
       "  'execution',\n",
       "  'exist',\n",
       "  'existence',\n",
       "  'exists',\n",
       "  'expect',\n",
       "  'expectations',\n",
       "  'expected',\n",
       "  'expecting',\n",
       "  'experience',\n",
       "  'experienced',\n",
       "  'experiences',\n",
       "  'experiment',\n",
       "  'expert',\n",
       "  'explain',\n",
       "  'explained',\n",
       "  'explains',\n",
       "  'explanation',\n",
       "  'exploitation',\n",
       "  'express',\n",
       "  'expression',\n",
       "  'extent',\n",
       "  'extra',\n",
       "  'extraordinary',\n",
       "  'extras',\n",
       "  'extreme',\n",
       "  'extremely',\n",
       "  'eye',\n",
       "  'eyes',\n",
       "  'f',\n",
       "  'fabulous',\n",
       "  'face',\n",
       "  'faces',\n",
       "  'facial',\n",
       "  'fact',\n",
       "  'factor',\n",
       "  'facts',\n",
       "  'fail',\n",
       "  'failed',\n",
       "  'fails',\n",
       "  'failure',\n",
       "  'fair',\n",
       "  'fairly',\n",
       "  'fairy',\n",
       "  'faith',\n",
       "  'faithful',\n",
       "  'fake',\n",
       "  'fall',\n",
       "  'fallen',\n",
       "  'falling',\n",
       "  'falls',\n",
       "  'false',\n",
       "  'fame',\n",
       "  'familiar',\n",
       "  'families',\n",
       "  'family',\n",
       "  'famous',\n",
       "  'fan',\n",
       "  'fans',\n",
       "  'fantastic',\n",
       "  'fantasy',\n",
       "  'far',\n",
       "  'fare',\n",
       "  'fascinating',\n",
       "  'fashion',\n",
       "  'fast',\n",
       "  'fat',\n",
       "  'fate',\n",
       "  'father',\n",
       "  \"father's\",\n",
       "  'fault',\n",
       "  'favor',\n",
       "  'favorite',\n",
       "  'favorites',\n",
       "  'favourite',\n",
       "  'fear',\n",
       "  'feature',\n",
       "  'featured',\n",
       "  'features',\n",
       "  'featuring',\n",
       "  'feel',\n",
       "  'feeling',\n",
       "  'feelings',\n",
       "  'feels',\n",
       "  'feet',\n",
       "  'fell',\n",
       "  'fellow',\n",
       "  'felt',\n",
       "  'female',\n",
       "  'festival',\n",
       "  'few',\n",
       "  'fiction',\n",
       "  'fictional',\n",
       "  'field',\n",
       "  'fight',\n",
       "  'fighting',\n",
       "  'fights',\n",
       "  'figure',\n",
       "  'figured',\n",
       "  ...],\n",
       " ['!',\n",
       "  '):',\n",
       "  ');',\n",
       "  '1',\n",
       "  '1/10',\n",
       "  '1/2',\n",
       "  '10',\n",
       "  '10/10',\n",
       "  '100',\n",
       "  '11',\n",
       "  '12',\n",
       "  '13',\n",
       "  '14',\n",
       "  '15',\n",
       "  '17',\n",
       "  '1950',\n",
       "  '1950s',\n",
       "  '1970',\n",
       "  '1980',\n",
       "  '2',\n",
       "  '20',\n",
       "  '2000',\n",
       "  '25',\n",
       "  '3',\n",
       "  '3/10',\n",
       "  '30',\n",
       "  '4',\n",
       "  '4/10',\n",
       "  '40',\n",
       "  '5',\n",
       "  '50',\n",
       "  '6',\n",
       "  '60',\n",
       "  '60s',\n",
       "  '7',\n",
       "  '7/10',\n",
       "  '70',\n",
       "  '70s',\n",
       "  '8',\n",
       "  '8/',\n",
       "  '80',\n",
       "  '80s',\n",
       "  '9',\n",
       "  '90',\n",
       "  ':)',\n",
       "  '?',\n",
       "  'a',\n",
       "  'abandoned',\n",
       "  'ability',\n",
       "  'able',\n",
       "  'about',\n",
       "  'above',\n",
       "  'absolute',\n",
       "  'absolutely',\n",
       "  'absurd',\n",
       "  'abuse',\n",
       "  'academy',\n",
       "  'accent',\n",
       "  'accents',\n",
       "  'accept',\n",
       "  'accident',\n",
       "  'accidentally',\n",
       "  'according',\n",
       "  'account',\n",
       "  'accurate',\n",
       "  'achieve',\n",
       "  'across',\n",
       "  'act',\n",
       "  'acted',\n",
       "  'acting',\n",
       "  'action',\n",
       "  'actions',\n",
       "  'actor',\n",
       "  'actors',\n",
       "  'actress',\n",
       "  'actresses',\n",
       "  'acts',\n",
       "  'actual',\n",
       "  'actually',\n",
       "  'adam',\n",
       "  'adaptation',\n",
       "  'add',\n",
       "  'added',\n",
       "  'adding',\n",
       "  'addition',\n",
       "  'adds',\n",
       "  'admit',\n",
       "  'adult',\n",
       "  'adults',\n",
       "  'adventure',\n",
       "  'adventures',\n",
       "  'advice',\n",
       "  'affair',\n",
       "  'afraid',\n",
       "  'africa',\n",
       "  'african',\n",
       "  'after',\n",
       "  'afternoon',\n",
       "  'again',\n",
       "  'against',\n",
       "  'age',\n",
       "  'agent',\n",
       "  'ages',\n",
       "  'ago',\n",
       "  'agree',\n",
       "  'ahead',\n",
       "  \"ain't\",\n",
       "  'air',\n",
       "  'aka',\n",
       "  'al',\n",
       "  'alan',\n",
       "  'alas',\n",
       "  'albert',\n",
       "  'alex',\n",
       "  'alice',\n",
       "  'alien',\n",
       "  'aliens',\n",
       "  'alive',\n",
       "  'all',\n",
       "  'allen',\n",
       "  'allow',\n",
       "  'allowed',\n",
       "  'allows',\n",
       "  'almost',\n",
       "  'alone',\n",
       "  'along',\n",
       "  'already',\n",
       "  'alright',\n",
       "  'also',\n",
       "  'although',\n",
       "  'always',\n",
       "  'am',\n",
       "  'amateur',\n",
       "  'amateurish',\n",
       "  'amazed',\n",
       "  'amazing',\n",
       "  'amazingly',\n",
       "  'america',\n",
       "  'american',\n",
       "  'americans',\n",
       "  'among',\n",
       "  'amongst',\n",
       "  'amount',\n",
       "  'amusing',\n",
       "  'an',\n",
       "  'ancient',\n",
       "  'and',\n",
       "  'anderson',\n",
       "  'andy',\n",
       "  'angel',\n",
       "  'angels',\n",
       "  'anger',\n",
       "  'angle',\n",
       "  'angles',\n",
       "  'angry',\n",
       "  'animal',\n",
       "  'animals',\n",
       "  'animated',\n",
       "  'animation',\n",
       "  'anime',\n",
       "  'ann',\n",
       "  'anna',\n",
       "  'anne',\n",
       "  'annoying',\n",
       "  'another',\n",
       "  'answer',\n",
       "  'answers',\n",
       "  'anthony',\n",
       "  'any',\n",
       "  'anybody',\n",
       "  'anymore',\n",
       "  'anyone',\n",
       "  'anything',\n",
       "  'anyway',\n",
       "  'anywhere',\n",
       "  'apart',\n",
       "  'apartment',\n",
       "  'apparent',\n",
       "  'apparently',\n",
       "  'appeal',\n",
       "  'appealing',\n",
       "  'appear',\n",
       "  'appearance',\n",
       "  'appeared',\n",
       "  'appears',\n",
       "  'appreciate',\n",
       "  'appreciated',\n",
       "  'approach',\n",
       "  'appropriate',\n",
       "  'are',\n",
       "  'area',\n",
       "  \"aren't\",\n",
       "  'arms',\n",
       "  'army',\n",
       "  'around',\n",
       "  'arrives',\n",
       "  'art',\n",
       "  'arthur',\n",
       "  'artist',\n",
       "  'artistic',\n",
       "  'artists',\n",
       "  'arts',\n",
       "  'as',\n",
       "  'ashamed',\n",
       "  'asian',\n",
       "  'aside',\n",
       "  'ask',\n",
       "  'asked',\n",
       "  'asking',\n",
       "  'asks',\n",
       "  'asleep',\n",
       "  'aspect',\n",
       "  'aspects',\n",
       "  'ass',\n",
       "  'assume',\n",
       "  'at',\n",
       "  'atmosphere',\n",
       "  'atrocious',\n",
       "  'attack',\n",
       "  'attacked',\n",
       "  'attacks',\n",
       "  'attempt',\n",
       "  'attempting',\n",
       "  'attempts',\n",
       "  'attention',\n",
       "  'attitude',\n",
       "  'attractive',\n",
       "  'audience',\n",
       "  'audiences',\n",
       "  'aunt',\n",
       "  'australian',\n",
       "  'authentic',\n",
       "  'author',\n",
       "  'available',\n",
       "  'average',\n",
       "  'avoid',\n",
       "  'award',\n",
       "  'awards',\n",
       "  'aware',\n",
       "  'away',\n",
       "  'awesome',\n",
       "  'awful',\n",
       "  'awkward',\n",
       "  'b',\n",
       "  'b-movie',\n",
       "  'baby',\n",
       "  'back',\n",
       "  'background',\n",
       "  'bad',\n",
       "  'badly',\n",
       "  'balance',\n",
       "  'ball',\n",
       "  'band',\n",
       "  'bank',\n",
       "  'bar',\n",
       "  'barbara',\n",
       "  'barely',\n",
       "  'base',\n",
       "  'baseball',\n",
       "  'based',\n",
       "  'basic',\n",
       "  'basically',\n",
       "  'basis',\n",
       "  'batman',\n",
       "  'battle',\n",
       "  'bbc',\n",
       "  'be',\n",
       "  'beach',\n",
       "  'bear',\n",
       "  'beast',\n",
       "  'beat',\n",
       "  'beautiful',\n",
       "  'beautifully',\n",
       "  'beauty',\n",
       "  'became',\n",
       "  'because',\n",
       "  'become',\n",
       "  'becomes',\n",
       "  'becoming',\n",
       "  'bed',\n",
       "  'been',\n",
       "  'before',\n",
       "  'began',\n",
       "  'begin',\n",
       "  'beginning',\n",
       "  'begins',\n",
       "  'behavior',\n",
       "  'behind',\n",
       "  'being',\n",
       "  'belief',\n",
       "  'believable',\n",
       "  'believe',\n",
       "  'believed',\n",
       "  'believes',\n",
       "  'beloved',\n",
       "  'below',\n",
       "  'ben',\n",
       "  'besides',\n",
       "  'best',\n",
       "  'bet',\n",
       "  'better',\n",
       "  'between',\n",
       "  'beyond',\n",
       "  'big',\n",
       "  'bigger',\n",
       "  'biggest',\n",
       "  'bill',\n",
       "  'billy',\n",
       "  'birth',\n",
       "  'bit',\n",
       "  'bits',\n",
       "  'bizarre',\n",
       "  'black',\n",
       "  'blah',\n",
       "  'blair',\n",
       "  'blame',\n",
       "  'bland',\n",
       "  'blind',\n",
       "  'blockbuster',\n",
       "  'blonde',\n",
       "  'blood',\n",
       "  'bloody',\n",
       "  'blow',\n",
       "  'blown',\n",
       "  'blue',\n",
       "  'board',\n",
       "  'boat',\n",
       "  'bob',\n",
       "  'bodies',\n",
       "  'body',\n",
       "  'bollywood',\n",
       "  'bomb',\n",
       "  'bond',\n",
       "  'book',\n",
       "  'books',\n",
       "  'bore',\n",
       "  'bored',\n",
       "  'boring',\n",
       "  'born',\n",
       "  'boss',\n",
       "  'both',\n",
       "  'bother',\n",
       "  'bothered',\n",
       "  'bottom',\n",
       "  'bought',\n",
       "  'bourne',\n",
       "  'box',\n",
       "  'boy',\n",
       "  'boyfriend',\n",
       "  'boys',\n",
       "  'brad',\n",
       "  'brain',\n",
       "  'brave',\n",
       "  'break',\n",
       "  'breaking',\n",
       "  'breaks',\n",
       "  'breath',\n",
       "  'breathtaking',\n",
       "  'brian',\n",
       "  'brief',\n",
       "  'bright',\n",
       "  'brilliant',\n",
       "  'brilliantly',\n",
       "  'bring',\n",
       "  'bringing',\n",
       "  'brings',\n",
       "  'british',\n",
       "  'broadway',\n",
       "  'broken',\n",
       "  'brooks',\n",
       "  'brother',\n",
       "  'brothers',\n",
       "  'brought',\n",
       "  'brown',\n",
       "  'bruce',\n",
       "  'brutal',\n",
       "  'buddy',\n",
       "  'budget',\n",
       "  'build',\n",
       "  'building',\n",
       "  'built',\n",
       "  'bunch',\n",
       "  'burns',\n",
       "  'burt',\n",
       "  'bus',\n",
       "  'business',\n",
       "  'busy',\n",
       "  'but',\n",
       "  'buy',\n",
       "  'buying',\n",
       "  'by',\n",
       "  'c',\n",
       "  'cabin',\n",
       "  'cable',\n",
       "  'cage',\n",
       "  'caine',\n",
       "  'california',\n",
       "  'call',\n",
       "  'called',\n",
       "  'calling',\n",
       "  'calls',\n",
       "  'came',\n",
       "  'cameo',\n",
       "  'camera',\n",
       "  'camp',\n",
       "  'campy',\n",
       "  'can',\n",
       "  \"can't\",\n",
       "  'canadian',\n",
       "  'candy',\n",
       "  'cannot',\n",
       "  'cant',\n",
       "  'capable',\n",
       "  'captain',\n",
       "  'capture',\n",
       "  'captured',\n",
       "  'captures',\n",
       "  'car',\n",
       "  'care',\n",
       "  'career',\n",
       "  'cares',\n",
       "  'caring',\n",
       "  'carried',\n",
       "  'carries',\n",
       "  'carry',\n",
       "  'carrying',\n",
       "  'cars',\n",
       "  'cartoon',\n",
       "  'cartoons',\n",
       "  'case',\n",
       "  'cases',\n",
       "  'cash',\n",
       "  'cast',\n",
       "  'casting',\n",
       "  'castle',\n",
       "  'cat',\n",
       "  'catch',\n",
       "  'category',\n",
       "  'caught',\n",
       "  'cause',\n",
       "  'caused',\n",
       "  'causes',\n",
       "  'cell',\n",
       "  'center',\n",
       "  'central',\n",
       "  'century',\n",
       "  'certain',\n",
       "  'certainly',\n",
       "  'cgi',\n",
       "  'challenge',\n",
       "  'chance',\n",
       "  'change',\n",
       "  'changed',\n",
       "  'changes',\n",
       "  'changing',\n",
       "  'channel',\n",
       "  'character',\n",
       "  \"character's\",\n",
       "  'characters',\n",
       "  'charge',\n",
       "  'charles',\n",
       "  'charlie',\n",
       "  'charm',\n",
       "  'charming',\n",
       "  'chase',\n",
       "  'che',\n",
       "  'cheap',\n",
       "  'check',\n",
       "  'cheesy',\n",
       "  'chemistry',\n",
       "  'chick',\n",
       "  'chief',\n",
       "  'child',\n",
       "  'childhood',\n",
       "  'children',\n",
       "  \"children's\",\n",
       "  'chilling',\n",
       "  'china',\n",
       "  'chinese',\n",
       "  'choice',\n",
       "  'choices',\n",
       "  'choose',\n",
       "  'chose',\n",
       "  'chosen',\n",
       "  'chris',\n",
       "  'christian',\n",
       "  'christmas',\n",
       "  'christopher',\n",
       "  'church',\n",
       "  'cinderella',\n",
       "  'cinema',\n",
       "  'cinematic',\n",
       "  'cinematography',\n",
       "  'circumstances',\n",
       "  'city',\n",
       "  'claim',\n",
       "  'claims',\n",
       "  'claire',\n",
       "  'clark',\n",
       "  'class',\n",
       "  'classic',\n",
       "  'classics',\n",
       "  'clean',\n",
       "  'clear',\n",
       "  'clearly',\n",
       "  'clever',\n",
       "  'clich',\n",
       "  'climax',\n",
       "  'clips',\n",
       "  'close',\n",
       "  'closer',\n",
       "  'closing',\n",
       "  'clothes',\n",
       "  'club',\n",
       "  'clue',\n",
       "  'code',\n",
       "  'cold',\n",
       "  'collection',\n",
       "  'college',\n",
       "  'color',\n",
       "  'colors',\n",
       "  'columbo',\n",
       "  'combination',\n",
       "  'combined',\n",
       "  'come',\n",
       "  'comedic',\n",
       "  'comedies',\n",
       "  'comedy',\n",
       "  'comes',\n",
       "  'comic',\n",
       "  'comical',\n",
       "  'coming',\n",
       "  'comment',\n",
       "  'commentary',\n",
       "  'comments',\n",
       "  'commercial',\n",
       "  'committed',\n",
       "  'common',\n",
       "  'community',\n",
       "  'company',\n",
       "  'compare',\n",
       "  'compared',\n",
       "  'comparison',\n",
       "  'compelling',\n",
       "  'complete',\n",
       "  'completely',\n",
       "  'complex',\n",
       "  'complicated',\n",
       "  'computer',\n",
       "  'concept',\n",
       "  'concerned',\n",
       "  'conclusion',\n",
       "  'conflict',\n",
       "  'confused',\n",
       "  'confusing',\n",
       "  'confusion',\n",
       "  'connection',\n",
       "  'consider',\n",
       "  'considered',\n",
       "  'considering',\n",
       "  'constant',\n",
       "  'constantly',\n",
       "  'contain',\n",
       "  'contains',\n",
       "  'contemporary',\n",
       "  'content',\n",
       "  'context',\n",
       "  'continue',\n",
       "  'continues',\n",
       "  'continuity',\n",
       "  'contrast',\n",
       "  'contrived',\n",
       "  'control',\n",
       "  'conversation',\n",
       "  'convey',\n",
       "  'convince',\n",
       "  'convinced',\n",
       "  'convincing',\n",
       "  'cool',\n",
       "  'cop',\n",
       "  'cops',\n",
       "  'copy',\n",
       "  'core',\n",
       "  'corny',\n",
       "  'correct',\n",
       "  'cost',\n",
       "  'costs',\n",
       "  'costume',\n",
       "  'costumes',\n",
       "  'could',\n",
       "  \"could've\",\n",
       "  \"couldn't\",\n",
       "  'count',\n",
       "  'country',\n",
       "  'couple',\n",
       "  'course',\n",
       "  'court',\n",
       "  'cover',\n",
       "  'covered',\n",
       "  'cowboy',\n",
       "  'crap',\n",
       "  'crappy',\n",
       "  'crash',\n",
       "  'crazy',\n",
       "  'create',\n",
       "  'created',\n",
       "  'creates',\n",
       "  'creating',\n",
       "  'creative',\n",
       "  'creature',\n",
       "  'creatures',\n",
       "  'credit',\n",
       "  'credits',\n",
       "  'creepy',\n",
       "  'crew',\n",
       "  'crime',\n",
       "  'criminal',\n",
       "  'criminals',\n",
       "  'critical',\n",
       "  'criticism',\n",
       "  'critics',\n",
       "  'cross',\n",
       "  'crowd',\n",
       "  'crude',\n",
       "  'cruel',\n",
       "  'cry',\n",
       "  'crying',\n",
       "  'cult',\n",
       "  'cultural',\n",
       "  'culture',\n",
       "  'curious',\n",
       "  'current',\n",
       "  'cut',\n",
       "  'cute',\n",
       "  'cuts',\n",
       "  'cutting',\n",
       "  'd',\n",
       "  'dad',\n",
       "  'daily',\n",
       "  'damn',\n",
       "  'dan',\n",
       "  'dance',\n",
       "  'dancing',\n",
       "  'danger',\n",
       "  'dangerous',\n",
       "  'daniel',\n",
       "  'danny',\n",
       "  'dark',\n",
       "  'darkness',\n",
       "  'date',\n",
       "  'dated',\n",
       "  'daughter',\n",
       "  'daughters',\n",
       "  'david',\n",
       "  'davis',\n",
       "  'day',\n",
       "  'days',\n",
       "  'de',\n",
       "  'dead',\n",
       "  'deadly',\n",
       "  'deal',\n",
       "  'dealing',\n",
       "  'deals',\n",
       "  'dean',\n",
       "  'death',\n",
       "  'deaths',\n",
       "  'debut',\n",
       "  'decade',\n",
       "  'decades',\n",
       "  'decent',\n",
       "  'decide',\n",
       "  'decided',\n",
       "  'decides',\n",
       "  'decision',\n",
       "  'deep',\n",
       "  'deeper',\n",
       "  'deeply',\n",
       "  'definitely',\n",
       "  'degree',\n",
       "  'delight',\n",
       "  'delightful',\n",
       "  'deliver',\n",
       "  'delivered',\n",
       "  'delivers',\n",
       "  'delivery',\n",
       "  'demon',\n",
       "  'demons',\n",
       "  'dennis',\n",
       "  'department',\n",
       "  'depicted',\n",
       "  'depiction',\n",
       "  'depressing',\n",
       "  'depth',\n",
       "  'describe',\n",
       "  'described',\n",
       "  'description',\n",
       "  'desert',\n",
       "  'deserve',\n",
       "  'deserved',\n",
       "  'deserves',\n",
       "  'design',\n",
       "  'designed',\n",
       "  'desire',\n",
       "  'desperate',\n",
       "  'desperately',\n",
       "  'despite',\n",
       "  'destroy',\n",
       "  'destroyed',\n",
       "  'detail',\n",
       "  'details',\n",
       "  'detective',\n",
       "  'determined',\n",
       "  'develop',\n",
       "  'developed',\n",
       "  'development',\n",
       "  'device',\n",
       "  'devil',\n",
       "  'dialog',\n",
       "  'dialogue',\n",
       "  'dick',\n",
       "  'did',\n",
       "  \"didn't\",\n",
       "  'die',\n",
       "  'died',\n",
       "  'dies',\n",
       "  'difference',\n",
       "  'different',\n",
       "  'difficult',\n",
       "  'direct',\n",
       "  'directed',\n",
       "  'directing',\n",
       "  'direction',\n",
       "  'directly',\n",
       "  'director',\n",
       "  \"director's\",\n",
       "  'directors',\n",
       "  'dirty',\n",
       "  'disappointed',\n",
       "  'disappointing',\n",
       "  'disappointment',\n",
       "  'disaster',\n",
       "  'disbelief',\n",
       "  'discover',\n",
       "  'discovered',\n",
       "  'discovers',\n",
       "  'disgusting',\n",
       "  'disney',\n",
       "  'display',\n",
       "  'disturbing',\n",
       "  'do',\n",
       "  'doctor',\n",
       "  'documentary',\n",
       "  'does',\n",
       "  \"doesn't\",\n",
       "  'dog',\n",
       "  'dogs',\n",
       "  'doing',\n",
       "  'dollar',\n",
       "  'dollars',\n",
       "  'don',\n",
       "  \"don't\",\n",
       "  'donald',\n",
       "  'done',\n",
       "  'door',\n",
       "  'double',\n",
       "  'doubt',\n",
       "  'douglas',\n",
       "  'down',\n",
       "  'downright',\n",
       "  'dozen',\n",
       "  'dr',\n",
       "  'drag',\n",
       "  'dragon',\n",
       "  'drama',\n",
       "  'dramatic',\n",
       "  'draw',\n",
       "  'drawn',\n",
       "  'dreadful',\n",
       "  'dream',\n",
       "  'dreams',\n",
       "  'dress',\n",
       "  'dressed',\n",
       "  'drew',\n",
       "  'drinking',\n",
       "  'drive',\n",
       "  'driven',\n",
       "  'driver',\n",
       "  'driving',\n",
       "  'drop',\n",
       "  'drug',\n",
       "  'drugs',\n",
       "  'drunk',\n",
       "  'dry',\n",
       "  'dubbed',\n",
       "  'dude',\n",
       "  'due',\n",
       "  'dull',\n",
       "  'dumb',\n",
       "  'during',\n",
       "  'dvd',\n",
       "  'dying',\n",
       "  'e',\n",
       "  'each',\n",
       "  'earlier',\n",
       "  'early',\n",
       "  'earth',\n",
       "  'easily',\n",
       "  'easy',\n",
       "  'eat',\n",
       "  'eating',\n",
       "  'ed',\n",
       "  'eddie',\n",
       "  'edge',\n",
       "  'edited',\n",
       "  'editing',\n",
       "  'edward',\n",
       "  'effect',\n",
       "  'effective',\n",
       "  'effectively',\n",
       "  'effects',\n",
       "  'effort',\n",
       "  'efforts',\n",
       "  'eight',\n",
       "  'either',\n",
       "  'element',\n",
       "  'elements',\n",
       "  'elizabeth',\n",
       "  'else',\n",
       "  'embarrassed',\n",
       "  'embarrassing',\n",
       "  'emma',\n",
       "  'emotion',\n",
       "  'emotional',\n",
       "  'emotionally',\n",
       "  'emotions',\n",
       "  'empty',\n",
       "  'encounter',\n",
       "  'end',\n",
       "  'ended',\n",
       "  'ending',\n",
       "  'endless',\n",
       "  'ends',\n",
       "  'enemy',\n",
       "  'energy',\n",
       "  'engaging',\n",
       "  'england',\n",
       "  'english',\n",
       "  'enjoy',\n",
       "  'enjoyable',\n",
       "  'enjoyed',\n",
       "  'enjoying',\n",
       "  'enough',\n",
       "  'enter',\n",
       "  'entertain',\n",
       "  'entertained',\n",
       "  'entertaining',\n",
       "  'entertainment',\n",
       "  'entire',\n",
       "  'entirely',\n",
       "  'environment',\n",
       "  'epic',\n",
       "  'episode',\n",
       "  'episodes',\n",
       "  'equally',\n",
       "  'era',\n",
       "  'eric',\n",
       "  'erotic',\n",
       "  'escape',\n",
       "  'escapes',\n",
       "  'especially',\n",
       "  'essential',\n",
       "  'essentially',\n",
       "  'established',\n",
       "  'etc',\n",
       "  'europe',\n",
       "  'european',\n",
       "  'even',\n",
       "  'evening',\n",
       "  'event',\n",
       "  'events',\n",
       "  'eventually',\n",
       "  'ever',\n",
       "  'every',\n",
       "  'everybody',\n",
       "  'everyday',\n",
       "  'everyone',\n",
       "  'everything',\n",
       "  'everywhere',\n",
       "  'evidence',\n",
       "  'evil',\n",
       "  'exact',\n",
       "  'exactly',\n",
       "  'example',\n",
       "  'examples',\n",
       "  'excellent',\n",
       "  'except',\n",
       "  'exception',\n",
       "  'excited',\n",
       "  'excitement',\n",
       "  'exciting',\n",
       "  'excuse',\n",
       "  'executed',\n",
       "  'execution',\n",
       "  'exist',\n",
       "  'existence',\n",
       "  'exists',\n",
       "  'expect',\n",
       "  'expectations',\n",
       "  'expected',\n",
       "  'expecting',\n",
       "  'experience',\n",
       "  'experienced',\n",
       "  'experiences',\n",
       "  'experiment',\n",
       "  'expert',\n",
       "  'explain',\n",
       "  'explained',\n",
       "  'explains',\n",
       "  'explanation',\n",
       "  'exploitation',\n",
       "  'express',\n",
       "  'expression',\n",
       "  'extent',\n",
       "  'extra',\n",
       "  'extraordinary',\n",
       "  'extras',\n",
       "  'extreme',\n",
       "  'extremely',\n",
       "  'eye',\n",
       "  'eyes',\n",
       "  'f',\n",
       "  'fabulous',\n",
       "  'face',\n",
       "  'faces',\n",
       "  'facial',\n",
       "  'fact',\n",
       "  'factor',\n",
       "  'facts',\n",
       "  'fail',\n",
       "  'failed',\n",
       "  'fails',\n",
       "  'failure',\n",
       "  'fair',\n",
       "  'fairly',\n",
       "  'fairy',\n",
       "  'faith',\n",
       "  'faithful',\n",
       "  'fake',\n",
       "  'fall',\n",
       "  'fallen',\n",
       "  'falling',\n",
       "  'falls',\n",
       "  'false',\n",
       "  'fame',\n",
       "  'familiar',\n",
       "  'families',\n",
       "  'family',\n",
       "  'famous',\n",
       "  'fan',\n",
       "  'fans',\n",
       "  'fantastic',\n",
       "  'fantasy',\n",
       "  'far',\n",
       "  'fare',\n",
       "  'fascinating',\n",
       "  'fashion',\n",
       "  'fast',\n",
       "  'fat',\n",
       "  'fate',\n",
       "  'father',\n",
       "  \"father's\",\n",
       "  'fault',\n",
       "  'favor',\n",
       "  'favorite',\n",
       "  'favorites',\n",
       "  'favourite',\n",
       "  'fear',\n",
       "  'feature',\n",
       "  'featured',\n",
       "  'features',\n",
       "  'featuring',\n",
       "  'feel',\n",
       "  'feeling',\n",
       "  'feelings',\n",
       "  'feels',\n",
       "  'feet',\n",
       "  'fell',\n",
       "  'fellow',\n",
       "  'felt',\n",
       "  'female',\n",
       "  'festival',\n",
       "  'few',\n",
       "  'fiction',\n",
       "  'fictional',\n",
       "  'field',\n",
       "  'fight',\n",
       "  'fighting',\n",
       "  'fights',\n",
       "  'figure',\n",
       "  'figured',\n",
       "  ...])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ww"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some great pre-computed matrices available online too. These aren't matrices of counts, but rather more abstract values computed using methods like those under discussion here. [GloVe](https://nlp.stanford.edu/projects/glove/) is a unsupervised learning algorithm that learns vector representations of words using word-to-word cooccurence matrices from a corpus. Let's explore them a bit and load in some [GloVe vectors](#GloVe-word-representations):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "glv = utils.build_glove(os.path.join(glove_home, 'glove.6B.50d.txt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vector comparisons form the heart of our analyses in this context. For the most part, we are interested in measuring the _distance_ between vectors. We surmise that semantically related words should be close together and semantically unrelated words should be far apart in the vector spaces we build."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Euclidean distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most basic and intuitive distance measure between vectors is __euclidean distance__. The euclidean distance between two vectors $u$ and $v$ of dimension $n$ is \n",
    "\n",
    "$$\\sqrt{\\sum_{i=1}^{n} |u_{i}-v_{i}|^2}$$ \n",
    "\n",
    "In two-dimensions, this corresponds to the length of the most direct line between the two points.\n",
    "\n",
    "As part of the exercise, implement this without using any other packages beyond what has been imported already."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean(u, v):    \n",
    "    \"\"\"Eculidean distance between 1d np.arrays `u` and `v`, which must \n",
    "    have the same dimensionality. Returns a float.\"\"\"\n",
    "    euclidean_sum = np.power(np.sum(np.power(np.absolute(np.diff(u-v)),2)),0.5)\n",
    "    return euclidean_sum "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The comment above shows how to define this measure yourself. The function used there is the __length__ of a vector $u$ of dimension $n$, which is defined as \n",
    "\n",
    "$$\\|u\\| = \\sqrt{\\sum_{i=1}^{n} u_{i}^{2}}$$ \n",
    "\n",
    "Please fill in vector_length below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_length(u):\n",
    "    \"\"\"Length (L2) of the 1d np.array `u`. Returns a new np.array with the \n",
    "    same dimensions as `u`.\"\"\"\n",
    "    vector_length = np.power(np.sum(np.power(u,2)),0.5)\n",
    "    return vector_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a tiny vector space:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a112d2c88>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ABC = np.array([\n",
    "    [ 1.0,  1.0],  # A\n",
    "    [9.0, 8.0],  # B\n",
    "    [10.0, 5.0]]) # C\n",
    "\n",
    "def plot_ABC(m):\n",
    "    plt.plot(m[:,0], m[:,1], marker='', linestyle='')\n",
    "    plt.xlim([0,np.max(m)*1.2])\n",
    "    plt.ylim([0,np.max(m)*1.2])\n",
    "    for i, x in enumerate(['A','B','C']):\n",
    "        plt.annotate(x, m[i,:])\n",
    "\n",
    "plot_ABC(ABC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The euclidean distances align well with the raw visual distance in the plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "euclidean(ABC[0], ABC[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "euclidean(ABC[1], ABC[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Length normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalization changes the affinity or distance between points A, B, and C dramatically. Is normalization the right thing to do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def length_norm(u):\n",
    "    \"\"\"L2 norm of the 1d np.array `u`. Returns a float.\"\"\"\n",
    "    return u / vector_length(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a1c1b3400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_ABC(np.array([length_norm(row) for row in ABC]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the connection between A and B is more apparent, as is the opposition between B and C."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cosine distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Cosine distance__ takes overall length into account. The cosine distance between two vectors $u$ and $v$ of dimension $n$ is \n",
    "\n",
    "$$1 - \\left(\\frac{\\sum_{i=1}^{n} u_{i} \\cdot v_{i}}{\\|u\\|\\cdot \\|v\\|}\\right)$$\n",
    "\n",
    "The similarity part of this (the righthand term of the subtraction) is actually measuring the _angles_ between the two vectors. The result is the same (in terms of rank order) as one gets from first normalizing both vectors using `vector_length` and then calculating their Euclidean distance.\n",
    "\n",
    "Implement this below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine(u, v):        \n",
    "    \"\"\"Cosine distance between 1d np.arrays `u` and `v`, which must have \n",
    "    the same dimensionality. Returns a float.\"\"\"\n",
    "    cosine_value = 1 - ((np.sum(u*v))/((vector_length(u)*vector_length(v))))\n",
    "    return cosine_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we set for ourselves the goal of associating A with B and disassociating B from C, in keeping with the semantic intuition expressed above. Then we can assess distance measures by whether they achieve this goal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      euclidean(A, B) =  1.00       euclidean(B, C) =  4.00\n",
      "         cosine(A, B) =  0.00          cosine(B, C) =  0.03\n"
     ]
    }
   ],
   "source": [
    "for m in (euclidean, cosine):\n",
    "    fmt = {'n': m.__name__,  \n",
    "           'AB': m(ABC[0], ABC[1]), \n",
    "           'BC': m(ABC[1], ABC[2])}\n",
    "    print('%(n)15s(A, B) = %(AB)5.2f %(n)15s(B, C) = %(BC)5.2f' % fmt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distributional neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `neighbors` function is an investigative aide. For a given `word`, it ranks all the words in the vocabulary `rownames` according to their distance from `word`, as measured by `distfunc` in matrix `mat`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neighbors(word, mat, rownames, distfunc=cosine):    \n",
    "    \"\"\"Tool for finding the nearest neighbors of `word` in `mat` according \n",
    "    to `distfunc`. The comparisons are between row vectors.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    word : str\n",
    "        The anchor word. Assumed to be in `rownames`.\n",
    "        \n",
    "    mat : np.array\n",
    "\n",
    "The vector-space model.\n",
    "        \n",
    "    rownames : list of str\n",
    "        The rownames of mat.\n",
    "            \n",
    "    distfunc : function mapping vector pairs to floats (default: `cosine`)\n",
    "        The measure of distance between vectors. Can also be `euclidean`, \n",
    "        `matching`, `jaccard`, as well as any other distance measure  \n",
    "        between 1d vectors.\n",
    "        \n",
    "    Raises\n",
    "    ------\n",
    "    ValueError\n",
    "        If word is not in rownames.\n",
    "    \n",
    "    Returns\n",
    "    -------    \n",
    "    list of tuples\n",
    "        The list is ordered by closeness to `word`. Each member is a pair \n",
    "        (word, distance) where word is a str and distance is a float.\n",
    "    \n",
    "    \"\"\"\n",
    "    if word not in rownames:\n",
    "        raise ValueError('%s is not in this VSM' % word)\n",
    "    w = mat[rownames.index(word)]\n",
    "    dists = [(rownames[i], distfunc(w, mat[i])) for i in range(len(mat))]\n",
    "    return sorted(dists, key=itemgetter(1), reverse=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By playing around with this function, you can start to get a sense for how the distance functions differ. Here are some example calls; you might try some new words to get a feel for what these matrices are like and how different words look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('superb', 0.0),\n",
       " ('excellent', 0.0026965023912962627),\n",
       " ('outstanding', 0.0027344413235226295),\n",
       " ('beautifully', 0.0027345163104325332),\n",
       " ('brilliant', 0.0027888643627086429)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neighbors(word='superb', mat=ww[0], rownames=ww[1], distfunc=cosine)[: 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('superb', 0.0),\n",
       " ('familiar', 2038.8175494634138),\n",
       " ('violent', 2208.9092330831522),\n",
       " ('follows', 2302.8996938642376),\n",
       " ('convincing', 2379.6657328288779)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neighbors(word='superb', mat=ww[0], rownames=ww[1], distfunc=euclidean)[: 5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above rankings actually tend to look pretty good, with `cosine` less likely to associate words that happen to have similar frequency. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The GloVe vectors look even better &mdash; but they are based on much more than just raw counts, as we'll see soon:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('superb', 2.2204460492503131e-16),\n",
       " ('brilliant', 0.15809110259014736),\n",
       " ('impressive', 0.19352861376442654),\n",
       " ('masterful', 0.22871323564771928),\n",
       " ('excellent', 0.22928471014596696)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neighbors(word='superb', mat=glv[0], rownames=glv[1], distfunc=cosine)[: 5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix reweighting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reweighting aims to amplify the important, trustworthy, and unusual, while deemphasizing the mundane and the quirky. The intuition behind moving away from raw counts is that just using frequency is too fuzzy a concept for our goal of encoding semantics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalization (row-wise or column-wise) is perhaps the simplest form of reweighting. With [length_norm](#Length-normalization), we normalize using `vector_length`. We can also normalize each row by the sum of its values, which turns each row into a probability distribution over the columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_norm(u):\n",
    "    \"\"\"Normalize 1d np.array `u` into a probability distribution. Assumes \n",
    "    that all the members of `u` are positive. Returns a 1d np.array of \n",
    "    the same dimensionality as `u`.\"\"\"\n",
    "\n",
    "    return u / np.sum(u)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Key Point: These normalization measures are insensitive to the _magnitude_ of the underlying counts. \n",
    "\n",
    "This is often a mistake in the messy world of large data sets; $[1,10]$ and $[1000,10000]$ are very different in ways that will be partly or totally obscured by normalization.\n",
    "\n",
    "How do we solve this? PMI!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pointwise Mutual Information [2 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Pointwise Mutual Information__ (PMI) addresses this issue, at least in part. The PMI for word $\\times$ context pair $(w,c)$ is \n",
    "\n",
    "$$\\log\\left(\\frac{P(w,c)}{P(w) \\cdot P(c)}\\right)$$\n",
    "\n",
    "with $\\log(0) = 0$. This is a measure of how far that cell's value deviates from what we would expect given the row and column sums for that cell. \n",
    "\n",
    "__Positive PMI__ (PPMI) maps all negative PMI values to 0.0. Our function `pmi` has `positive=True` as a default, in light of the arguments in [Levy and Goldberg 2014](http://papers.nips.cc/paper/5477-neural-word-embedding-as-implicit-matrix-factorization), section 3.3.\n",
    "\n",
    "For the last part of the exercise, we want to you implement `pmi` and the `pmi_log` helper functions. We have given you a couple of comments to help you with this. If you don't finish this part, finish it for the homework. This will be worth 2 points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pmi(mat, rownames=None, positive=True):\n",
    "    \"\"\"Pointwise Mutual Information with Positive on by default.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    mat : 2d np.array\n",
    "       The matrix to operate on.\n",
    "           \n",
    "    rownames : list of str or None\n",
    "        Not used; it's an argument only for consistency with other methods \n",
    "        defined here.\n",
    "        \n",
    "    positive : bool (default: True)\n",
    "        Implements Positive PMI.\n",
    "        \n",
    "    Returns\n",
    "    -------    \n",
    "    (np.array, list of str)\n",
    "       The first member is the PMI-transformed version of `mat`, and the \n",
    "       second member is `rownames` (unchanged).\n",
    "    \n",
    "    \"\"\"    \n",
    "    # Joint probability table:\n",
    "    # Pre-compute column sums:\n",
    "    # Vectorize this function so that it can be applied rowwise:   \n",
    "    \n",
    "    p_join= prob_norm(mat)\n",
    "    p_column = np.sum(p_join,axis=1)\n",
    "    p_row = np.sum(p_join,axis=0)\n",
    "    p = p_join/(p_column*p_row)\n",
    "    pmi= _pmi_log(p,positive)\n",
    "    return (pmi, rownames)\n",
    "\n",
    "def _pmi_log(x, positive=True):\n",
    "    \"\"\"With `positive=False`, return log(x) if possible, else 0.\n",
    "    With `positive=True`, log(x) is mapped to 0 where negative.\"\"\"\n",
    "    #To avoid divide by 0 run-time errors\n",
    "    x[x<=0] = 1 \n",
    "    \n",
    "    log_x = np.log(x)\n",
    "     \n",
    "    if positive:\n",
    "        log_x[log_x <0] = 0\n",
    "        \n",
    "    return log_x\n",
    "    \n",
    "#     if positive == False:\n",
    "#         if np.all(x>0):\n",
    "#             return log(x)\n",
    "#         else:\n",
    "#             return np.zeros(x.shape)\n",
    "   \n",
    "#     elif positive == True:\n",
    "#         if(np.any(np.log(x)<=0)):\n",
    "#             return np.zeros(x.shape)\n",
    "#         else:\n",
    "#             return log(x)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we reweight the word $\\times$ word IMDB matrix from above using PPMI:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "ww_ppmi = pmi(mat=ww[0],  rownames=ww[1], positive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 2.9206272 ,  4.86822348,  4.57491464, ...,  5.72509599,\n",
       "          3.86289286,  4.51548935],\n",
       "        [ 0.        ,  4.83661814,  0.68309434, ...,  0.66250096,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  1.06156099,  4.64284875, ...,  1.64333021,\n",
       "          0.        ,  0.        ],\n",
       "        ..., \n",
       "        [ 0.        ,  0.55073536,  0.56531131, ...,  5.11684825,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.55073536,  0.        , ...,  2.202946  ,\n",
       "          4.58962359,  4.82297405],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.66250096,\n",
       "          3.3663241 ,  4.68984274]]),\n",
       " ['!',\n",
       "  '):',\n",
       "  ');',\n",
       "  '1',\n",
       "  '1/10',\n",
       "  '1/2',\n",
       "  '10',\n",
       "  '10/10',\n",
       "  '100',\n",
       "  '11',\n",
       "  '12',\n",
       "  '13',\n",
       "  '14',\n",
       "  '15',\n",
       "  '17',\n",
       "  '1950',\n",
       "  '1950s',\n",
       "  '1970',\n",
       "  '1980',\n",
       "  '2',\n",
       "  '20',\n",
       "  '2000',\n",
       "  '25',\n",
       "  '3',\n",
       "  '3/10',\n",
       "  '30',\n",
       "  '4',\n",
       "  '4/10',\n",
       "  '40',\n",
       "  '5',\n",
       "  '50',\n",
       "  '6',\n",
       "  '60',\n",
       "  '60s',\n",
       "  '7',\n",
       "  '7/10',\n",
       "  '70',\n",
       "  '70s',\n",
       "  '8',\n",
       "  '8/',\n",
       "  '80',\n",
       "  '80s',\n",
       "  '9',\n",
       "  '90',\n",
       "  ':)',\n",
       "  '?',\n",
       "  'a',\n",
       "  'abandoned',\n",
       "  'ability',\n",
       "  'able',\n",
       "  'about',\n",
       "  'above',\n",
       "  'absolute',\n",
       "  'absolutely',\n",
       "  'absurd',\n",
       "  'abuse',\n",
       "  'academy',\n",
       "  'accent',\n",
       "  'accents',\n",
       "  'accept',\n",
       "  'accident',\n",
       "  'accidentally',\n",
       "  'according',\n",
       "  'account',\n",
       "  'accurate',\n",
       "  'achieve',\n",
       "  'across',\n",
       "  'act',\n",
       "  'acted',\n",
       "  'acting',\n",
       "  'action',\n",
       "  'actions',\n",
       "  'actor',\n",
       "  'actors',\n",
       "  'actress',\n",
       "  'actresses',\n",
       "  'acts',\n",
       "  'actual',\n",
       "  'actually',\n",
       "  'adam',\n",
       "  'adaptation',\n",
       "  'add',\n",
       "  'added',\n",
       "  'adding',\n",
       "  'addition',\n",
       "  'adds',\n",
       "  'admit',\n",
       "  'adult',\n",
       "  'adults',\n",
       "  'adventure',\n",
       "  'adventures',\n",
       "  'advice',\n",
       "  'affair',\n",
       "  'afraid',\n",
       "  'africa',\n",
       "  'african',\n",
       "  'after',\n",
       "  'afternoon',\n",
       "  'again',\n",
       "  'against',\n",
       "  'age',\n",
       "  'agent',\n",
       "  'ages',\n",
       "  'ago',\n",
       "  'agree',\n",
       "  'ahead',\n",
       "  \"ain't\",\n",
       "  'air',\n",
       "  'aka',\n",
       "  'al',\n",
       "  'alan',\n",
       "  'alas',\n",
       "  'albert',\n",
       "  'alex',\n",
       "  'alice',\n",
       "  'alien',\n",
       "  'aliens',\n",
       "  'alive',\n",
       "  'all',\n",
       "  'allen',\n",
       "  'allow',\n",
       "  'allowed',\n",
       "  'allows',\n",
       "  'almost',\n",
       "  'alone',\n",
       "  'along',\n",
       "  'already',\n",
       "  'alright',\n",
       "  'also',\n",
       "  'although',\n",
       "  'always',\n",
       "  'am',\n",
       "  'amateur',\n",
       "  'amateurish',\n",
       "  'amazed',\n",
       "  'amazing',\n",
       "  'amazingly',\n",
       "  'america',\n",
       "  'american',\n",
       "  'americans',\n",
       "  'among',\n",
       "  'amongst',\n",
       "  'amount',\n",
       "  'amusing',\n",
       "  'an',\n",
       "  'ancient',\n",
       "  'and',\n",
       "  'anderson',\n",
       "  'andy',\n",
       "  'angel',\n",
       "  'angels',\n",
       "  'anger',\n",
       "  'angle',\n",
       "  'angles',\n",
       "  'angry',\n",
       "  'animal',\n",
       "  'animals',\n",
       "  'animated',\n",
       "  'animation',\n",
       "  'anime',\n",
       "  'ann',\n",
       "  'anna',\n",
       "  'anne',\n",
       "  'annoying',\n",
       "  'another',\n",
       "  'answer',\n",
       "  'answers',\n",
       "  'anthony',\n",
       "  'any',\n",
       "  'anybody',\n",
       "  'anymore',\n",
       "  'anyone',\n",
       "  'anything',\n",
       "  'anyway',\n",
       "  'anywhere',\n",
       "  'apart',\n",
       "  'apartment',\n",
       "  'apparent',\n",
       "  'apparently',\n",
       "  'appeal',\n",
       "  'appealing',\n",
       "  'appear',\n",
       "  'appearance',\n",
       "  'appeared',\n",
       "  'appears',\n",
       "  'appreciate',\n",
       "  'appreciated',\n",
       "  'approach',\n",
       "  'appropriate',\n",
       "  'are',\n",
       "  'area',\n",
       "  \"aren't\",\n",
       "  'arms',\n",
       "  'army',\n",
       "  'around',\n",
       "  'arrives',\n",
       "  'art',\n",
       "  'arthur',\n",
       "  'artist',\n",
       "  'artistic',\n",
       "  'artists',\n",
       "  'arts',\n",
       "  'as',\n",
       "  'ashamed',\n",
       "  'asian',\n",
       "  'aside',\n",
       "  'ask',\n",
       "  'asked',\n",
       "  'asking',\n",
       "  'asks',\n",
       "  'asleep',\n",
       "  'aspect',\n",
       "  'aspects',\n",
       "  'ass',\n",
       "  'assume',\n",
       "  'at',\n",
       "  'atmosphere',\n",
       "  'atrocious',\n",
       "  'attack',\n",
       "  'attacked',\n",
       "  'attacks',\n",
       "  'attempt',\n",
       "  'attempting',\n",
       "  'attempts',\n",
       "  'attention',\n",
       "  'attitude',\n",
       "  'attractive',\n",
       "  'audience',\n",
       "  'audiences',\n",
       "  'aunt',\n",
       "  'australian',\n",
       "  'authentic',\n",
       "  'author',\n",
       "  'available',\n",
       "  'average',\n",
       "  'avoid',\n",
       "  'award',\n",
       "  'awards',\n",
       "  'aware',\n",
       "  'away',\n",
       "  'awesome',\n",
       "  'awful',\n",
       "  'awkward',\n",
       "  'b',\n",
       "  'b-movie',\n",
       "  'baby',\n",
       "  'back',\n",
       "  'background',\n",
       "  'bad',\n",
       "  'badly',\n",
       "  'balance',\n",
       "  'ball',\n",
       "  'band',\n",
       "  'bank',\n",
       "  'bar',\n",
       "  'barbara',\n",
       "  'barely',\n",
       "  'base',\n",
       "  'baseball',\n",
       "  'based',\n",
       "  'basic',\n",
       "  'basically',\n",
       "  'basis',\n",
       "  'batman',\n",
       "  'battle',\n",
       "  'bbc',\n",
       "  'be',\n",
       "  'beach',\n",
       "  'bear',\n",
       "  'beast',\n",
       "  'beat',\n",
       "  'beautiful',\n",
       "  'beautifully',\n",
       "  'beauty',\n",
       "  'became',\n",
       "  'because',\n",
       "  'become',\n",
       "  'becomes',\n",
       "  'becoming',\n",
       "  'bed',\n",
       "  'been',\n",
       "  'before',\n",
       "  'began',\n",
       "  'begin',\n",
       "  'beginning',\n",
       "  'begins',\n",
       "  'behavior',\n",
       "  'behind',\n",
       "  'being',\n",
       "  'belief',\n",
       "  'believable',\n",
       "  'believe',\n",
       "  'believed',\n",
       "  'believes',\n",
       "  'beloved',\n",
       "  'below',\n",
       "  'ben',\n",
       "  'besides',\n",
       "  'best',\n",
       "  'bet',\n",
       "  'better',\n",
       "  'between',\n",
       "  'beyond',\n",
       "  'big',\n",
       "  'bigger',\n",
       "  'biggest',\n",
       "  'bill',\n",
       "  'billy',\n",
       "  'birth',\n",
       "  'bit',\n",
       "  'bits',\n",
       "  'bizarre',\n",
       "  'black',\n",
       "  'blah',\n",
       "  'blair',\n",
       "  'blame',\n",
       "  'bland',\n",
       "  'blind',\n",
       "  'blockbuster',\n",
       "  'blonde',\n",
       "  'blood',\n",
       "  'bloody',\n",
       "  'blow',\n",
       "  'blown',\n",
       "  'blue',\n",
       "  'board',\n",
       "  'boat',\n",
       "  'bob',\n",
       "  'bodies',\n",
       "  'body',\n",
       "  'bollywood',\n",
       "  'bomb',\n",
       "  'bond',\n",
       "  'book',\n",
       "  'books',\n",
       "  'bore',\n",
       "  'bored',\n",
       "  'boring',\n",
       "  'born',\n",
       "  'boss',\n",
       "  'both',\n",
       "  'bother',\n",
       "  'bothered',\n",
       "  'bottom',\n",
       "  'bought',\n",
       "  'bourne',\n",
       "  'box',\n",
       "  'boy',\n",
       "  'boyfriend',\n",
       "  'boys',\n",
       "  'brad',\n",
       "  'brain',\n",
       "  'brave',\n",
       "  'break',\n",
       "  'breaking',\n",
       "  'breaks',\n",
       "  'breath',\n",
       "  'breathtaking',\n",
       "  'brian',\n",
       "  'brief',\n",
       "  'bright',\n",
       "  'brilliant',\n",
       "  'brilliantly',\n",
       "  'bring',\n",
       "  'bringing',\n",
       "  'brings',\n",
       "  'british',\n",
       "  'broadway',\n",
       "  'broken',\n",
       "  'brooks',\n",
       "  'brother',\n",
       "  'brothers',\n",
       "  'brought',\n",
       "  'brown',\n",
       "  'bruce',\n",
       "  'brutal',\n",
       "  'buddy',\n",
       "  'budget',\n",
       "  'build',\n",
       "  'building',\n",
       "  'built',\n",
       "  'bunch',\n",
       "  'burns',\n",
       "  'burt',\n",
       "  'bus',\n",
       "  'business',\n",
       "  'busy',\n",
       "  'but',\n",
       "  'buy',\n",
       "  'buying',\n",
       "  'by',\n",
       "  'c',\n",
       "  'cabin',\n",
       "  'cable',\n",
       "  'cage',\n",
       "  'caine',\n",
       "  'california',\n",
       "  'call',\n",
       "  'called',\n",
       "  'calling',\n",
       "  'calls',\n",
       "  'came',\n",
       "  'cameo',\n",
       "  'camera',\n",
       "  'camp',\n",
       "  'campy',\n",
       "  'can',\n",
       "  \"can't\",\n",
       "  'canadian',\n",
       "  'candy',\n",
       "  'cannot',\n",
       "  'cant',\n",
       "  'capable',\n",
       "  'captain',\n",
       "  'capture',\n",
       "  'captured',\n",
       "  'captures',\n",
       "  'car',\n",
       "  'care',\n",
       "  'career',\n",
       "  'cares',\n",
       "  'caring',\n",
       "  'carried',\n",
       "  'carries',\n",
       "  'carry',\n",
       "  'carrying',\n",
       "  'cars',\n",
       "  'cartoon',\n",
       "  'cartoons',\n",
       "  'case',\n",
       "  'cases',\n",
       "  'cash',\n",
       "  'cast',\n",
       "  'casting',\n",
       "  'castle',\n",
       "  'cat',\n",
       "  'catch',\n",
       "  'category',\n",
       "  'caught',\n",
       "  'cause',\n",
       "  'caused',\n",
       "  'causes',\n",
       "  'cell',\n",
       "  'center',\n",
       "  'central',\n",
       "  'century',\n",
       "  'certain',\n",
       "  'certainly',\n",
       "  'cgi',\n",
       "  'challenge',\n",
       "  'chance',\n",
       "  'change',\n",
       "  'changed',\n",
       "  'changes',\n",
       "  'changing',\n",
       "  'channel',\n",
       "  'character',\n",
       "  \"character's\",\n",
       "  'characters',\n",
       "  'charge',\n",
       "  'charles',\n",
       "  'charlie',\n",
       "  'charm',\n",
       "  'charming',\n",
       "  'chase',\n",
       "  'che',\n",
       "  'cheap',\n",
       "  'check',\n",
       "  'cheesy',\n",
       "  'chemistry',\n",
       "  'chick',\n",
       "  'chief',\n",
       "  'child',\n",
       "  'childhood',\n",
       "  'children',\n",
       "  \"children's\",\n",
       "  'chilling',\n",
       "  'china',\n",
       "  'chinese',\n",
       "  'choice',\n",
       "  'choices',\n",
       "  'choose',\n",
       "  'chose',\n",
       "  'chosen',\n",
       "  'chris',\n",
       "  'christian',\n",
       "  'christmas',\n",
       "  'christopher',\n",
       "  'church',\n",
       "  'cinderella',\n",
       "  'cinema',\n",
       "  'cinematic',\n",
       "  'cinematography',\n",
       "  'circumstances',\n",
       "  'city',\n",
       "  'claim',\n",
       "  'claims',\n",
       "  'claire',\n",
       "  'clark',\n",
       "  'class',\n",
       "  'classic',\n",
       "  'classics',\n",
       "  'clean',\n",
       "  'clear',\n",
       "  'clearly',\n",
       "  'clever',\n",
       "  'clich',\n",
       "  'climax',\n",
       "  'clips',\n",
       "  'close',\n",
       "  'closer',\n",
       "  'closing',\n",
       "  'clothes',\n",
       "  'club',\n",
       "  'clue',\n",
       "  'code',\n",
       "  'cold',\n",
       "  'collection',\n",
       "  'college',\n",
       "  'color',\n",
       "  'colors',\n",
       "  'columbo',\n",
       "  'combination',\n",
       "  'combined',\n",
       "  'come',\n",
       "  'comedic',\n",
       "  'comedies',\n",
       "  'comedy',\n",
       "  'comes',\n",
       "  'comic',\n",
       "  'comical',\n",
       "  'coming',\n",
       "  'comment',\n",
       "  'commentary',\n",
       "  'comments',\n",
       "  'commercial',\n",
       "  'committed',\n",
       "  'common',\n",
       "  'community',\n",
       "  'company',\n",
       "  'compare',\n",
       "  'compared',\n",
       "  'comparison',\n",
       "  'compelling',\n",
       "  'complete',\n",
       "  'completely',\n",
       "  'complex',\n",
       "  'complicated',\n",
       "  'computer',\n",
       "  'concept',\n",
       "  'concerned',\n",
       "  'conclusion',\n",
       "  'conflict',\n",
       "  'confused',\n",
       "  'confusing',\n",
       "  'confusion',\n",
       "  'connection',\n",
       "  'consider',\n",
       "  'considered',\n",
       "  'considering',\n",
       "  'constant',\n",
       "  'constantly',\n",
       "  'contain',\n",
       "  'contains',\n",
       "  'contemporary',\n",
       "  'content',\n",
       "  'context',\n",
       "  'continue',\n",
       "  'continues',\n",
       "  'continuity',\n",
       "  'contrast',\n",
       "  'contrived',\n",
       "  'control',\n",
       "  'conversation',\n",
       "  'convey',\n",
       "  'convince',\n",
       "  'convinced',\n",
       "  'convincing',\n",
       "  'cool',\n",
       "  'cop',\n",
       "  'cops',\n",
       "  'copy',\n",
       "  'core',\n",
       "  'corny',\n",
       "  'correct',\n",
       "  'cost',\n",
       "  'costs',\n",
       "  'costume',\n",
       "  'costumes',\n",
       "  'could',\n",
       "  \"could've\",\n",
       "  \"couldn't\",\n",
       "  'count',\n",
       "  'country',\n",
       "  'couple',\n",
       "  'course',\n",
       "  'court',\n",
       "  'cover',\n",
       "  'covered',\n",
       "  'cowboy',\n",
       "  'crap',\n",
       "  'crappy',\n",
       "  'crash',\n",
       "  'crazy',\n",
       "  'create',\n",
       "  'created',\n",
       "  'creates',\n",
       "  'creating',\n",
       "  'creative',\n",
       "  'creature',\n",
       "  'creatures',\n",
       "  'credit',\n",
       "  'credits',\n",
       "  'creepy',\n",
       "  'crew',\n",
       "  'crime',\n",
       "  'criminal',\n",
       "  'criminals',\n",
       "  'critical',\n",
       "  'criticism',\n",
       "  'critics',\n",
       "  'cross',\n",
       "  'crowd',\n",
       "  'crude',\n",
       "  'cruel',\n",
       "  'cry',\n",
       "  'crying',\n",
       "  'cult',\n",
       "  'cultural',\n",
       "  'culture',\n",
       "  'curious',\n",
       "  'current',\n",
       "  'cut',\n",
       "  'cute',\n",
       "  'cuts',\n",
       "  'cutting',\n",
       "  'd',\n",
       "  'dad',\n",
       "  'daily',\n",
       "  'damn',\n",
       "  'dan',\n",
       "  'dance',\n",
       "  'dancing',\n",
       "  'danger',\n",
       "  'dangerous',\n",
       "  'daniel',\n",
       "  'danny',\n",
       "  'dark',\n",
       "  'darkness',\n",
       "  'date',\n",
       "  'dated',\n",
       "  'daughter',\n",
       "  'daughters',\n",
       "  'david',\n",
       "  'davis',\n",
       "  'day',\n",
       "  'days',\n",
       "  'de',\n",
       "  'dead',\n",
       "  'deadly',\n",
       "  'deal',\n",
       "  'dealing',\n",
       "  'deals',\n",
       "  'dean',\n",
       "  'death',\n",
       "  'deaths',\n",
       "  'debut',\n",
       "  'decade',\n",
       "  'decades',\n",
       "  'decent',\n",
       "  'decide',\n",
       "  'decided',\n",
       "  'decides',\n",
       "  'decision',\n",
       "  'deep',\n",
       "  'deeper',\n",
       "  'deeply',\n",
       "  'definitely',\n",
       "  'degree',\n",
       "  'delight',\n",
       "  'delightful',\n",
       "  'deliver',\n",
       "  'delivered',\n",
       "  'delivers',\n",
       "  'delivery',\n",
       "  'demon',\n",
       "  'demons',\n",
       "  'dennis',\n",
       "  'department',\n",
       "  'depicted',\n",
       "  'depiction',\n",
       "  'depressing',\n",
       "  'depth',\n",
       "  'describe',\n",
       "  'described',\n",
       "  'description',\n",
       "  'desert',\n",
       "  'deserve',\n",
       "  'deserved',\n",
       "  'deserves',\n",
       "  'design',\n",
       "  'designed',\n",
       "  'desire',\n",
       "  'desperate',\n",
       "  'desperately',\n",
       "  'despite',\n",
       "  'destroy',\n",
       "  'destroyed',\n",
       "  'detail',\n",
       "  'details',\n",
       "  'detective',\n",
       "  'determined',\n",
       "  'develop',\n",
       "  'developed',\n",
       "  'development',\n",
       "  'device',\n",
       "  'devil',\n",
       "  'dialog',\n",
       "  'dialogue',\n",
       "  'dick',\n",
       "  'did',\n",
       "  \"didn't\",\n",
       "  'die',\n",
       "  'died',\n",
       "  'dies',\n",
       "  'difference',\n",
       "  'different',\n",
       "  'difficult',\n",
       "  'direct',\n",
       "  'directed',\n",
       "  'directing',\n",
       "  'direction',\n",
       "  'directly',\n",
       "  'director',\n",
       "  \"director's\",\n",
       "  'directors',\n",
       "  'dirty',\n",
       "  'disappointed',\n",
       "  'disappointing',\n",
       "  'disappointment',\n",
       "  'disaster',\n",
       "  'disbelief',\n",
       "  'discover',\n",
       "  'discovered',\n",
       "  'discovers',\n",
       "  'disgusting',\n",
       "  'disney',\n",
       "  'display',\n",
       "  'disturbing',\n",
       "  'do',\n",
       "  'doctor',\n",
       "  'documentary',\n",
       "  'does',\n",
       "  \"doesn't\",\n",
       "  'dog',\n",
       "  'dogs',\n",
       "  'doing',\n",
       "  'dollar',\n",
       "  'dollars',\n",
       "  'don',\n",
       "  \"don't\",\n",
       "  'donald',\n",
       "  'done',\n",
       "  'door',\n",
       "  'double',\n",
       "  'doubt',\n",
       "  'douglas',\n",
       "  'down',\n",
       "  'downright',\n",
       "  'dozen',\n",
       "  'dr',\n",
       "  'drag',\n",
       "  'dragon',\n",
       "  'drama',\n",
       "  'dramatic',\n",
       "  'draw',\n",
       "  'drawn',\n",
       "  'dreadful',\n",
       "  'dream',\n",
       "  'dreams',\n",
       "  'dress',\n",
       "  'dressed',\n",
       "  'drew',\n",
       "  'drinking',\n",
       "  'drive',\n",
       "  'driven',\n",
       "  'driver',\n",
       "  'driving',\n",
       "  'drop',\n",
       "  'drug',\n",
       "  'drugs',\n",
       "  'drunk',\n",
       "  'dry',\n",
       "  'dubbed',\n",
       "  'dude',\n",
       "  'due',\n",
       "  'dull',\n",
       "  'dumb',\n",
       "  'during',\n",
       "  'dvd',\n",
       "  'dying',\n",
       "  'e',\n",
       "  'each',\n",
       "  'earlier',\n",
       "  'early',\n",
       "  'earth',\n",
       "  'easily',\n",
       "  'easy',\n",
       "  'eat',\n",
       "  'eating',\n",
       "  'ed',\n",
       "  'eddie',\n",
       "  'edge',\n",
       "  'edited',\n",
       "  'editing',\n",
       "  'edward',\n",
       "  'effect',\n",
       "  'effective',\n",
       "  'effectively',\n",
       "  'effects',\n",
       "  'effort',\n",
       "  'efforts',\n",
       "  'eight',\n",
       "  'either',\n",
       "  'element',\n",
       "  'elements',\n",
       "  'elizabeth',\n",
       "  'else',\n",
       "  'embarrassed',\n",
       "  'embarrassing',\n",
       "  'emma',\n",
       "  'emotion',\n",
       "  'emotional',\n",
       "  'emotionally',\n",
       "  'emotions',\n",
       "  'empty',\n",
       "  'encounter',\n",
       "  'end',\n",
       "  'ended',\n",
       "  'ending',\n",
       "  'endless',\n",
       "  'ends',\n",
       "  'enemy',\n",
       "  'energy',\n",
       "  'engaging',\n",
       "  'england',\n",
       "  'english',\n",
       "  'enjoy',\n",
       "  'enjoyable',\n",
       "  'enjoyed',\n",
       "  'enjoying',\n",
       "  'enough',\n",
       "  'enter',\n",
       "  'entertain',\n",
       "  'entertained',\n",
       "  'entertaining',\n",
       "  'entertainment',\n",
       "  'entire',\n",
       "  'entirely',\n",
       "  'environment',\n",
       "  'epic',\n",
       "  'episode',\n",
       "  'episodes',\n",
       "  'equally',\n",
       "  'era',\n",
       "  'eric',\n",
       "  'erotic',\n",
       "  'escape',\n",
       "  'escapes',\n",
       "  'especially',\n",
       "  'essential',\n",
       "  'essentially',\n",
       "  'established',\n",
       "  'etc',\n",
       "  'europe',\n",
       "  'european',\n",
       "  'even',\n",
       "  'evening',\n",
       "  'event',\n",
       "  'events',\n",
       "  'eventually',\n",
       "  'ever',\n",
       "  'every',\n",
       "  'everybody',\n",
       "  'everyday',\n",
       "  'everyone',\n",
       "  'everything',\n",
       "  'everywhere',\n",
       "  'evidence',\n",
       "  'evil',\n",
       "  'exact',\n",
       "  'exactly',\n",
       "  'example',\n",
       "  'examples',\n",
       "  'excellent',\n",
       "  'except',\n",
       "  'exception',\n",
       "  'excited',\n",
       "  'excitement',\n",
       "  'exciting',\n",
       "  'excuse',\n",
       "  'executed',\n",
       "  'execution',\n",
       "  'exist',\n",
       "  'existence',\n",
       "  'exists',\n",
       "  'expect',\n",
       "  'expectations',\n",
       "  'expected',\n",
       "  'expecting',\n",
       "  'experience',\n",
       "  'experienced',\n",
       "  'experiences',\n",
       "  'experiment',\n",
       "  'expert',\n",
       "  'explain',\n",
       "  'explained',\n",
       "  'explains',\n",
       "  'explanation',\n",
       "  'exploitation',\n",
       "  'express',\n",
       "  'expression',\n",
       "  'extent',\n",
       "  'extra',\n",
       "  'extraordinary',\n",
       "  'extras',\n",
       "  'extreme',\n",
       "  'extremely',\n",
       "  'eye',\n",
       "  'eyes',\n",
       "  'f',\n",
       "  'fabulous',\n",
       "  'face',\n",
       "  'faces',\n",
       "  'facial',\n",
       "  'fact',\n",
       "  'factor',\n",
       "  'facts',\n",
       "  'fail',\n",
       "  'failed',\n",
       "  'fails',\n",
       "  'failure',\n",
       "  'fair',\n",
       "  'fairly',\n",
       "  'fairy',\n",
       "  'faith',\n",
       "  'faithful',\n",
       "  'fake',\n",
       "  'fall',\n",
       "  'fallen',\n",
       "  'falling',\n",
       "  'falls',\n",
       "  'false',\n",
       "  'fame',\n",
       "  'familiar',\n",
       "  'families',\n",
       "  'family',\n",
       "  'famous',\n",
       "  'fan',\n",
       "  'fans',\n",
       "  'fantastic',\n",
       "  'fantasy',\n",
       "  'far',\n",
       "  'fare',\n",
       "  'fascinating',\n",
       "  'fashion',\n",
       "  'fast',\n",
       "  'fat',\n",
       "  'fate',\n",
       "  'father',\n",
       "  \"father's\",\n",
       "  'fault',\n",
       "  'favor',\n",
       "  'favorite',\n",
       "  'favorites',\n",
       "  'favourite',\n",
       "  'fear',\n",
       "  'feature',\n",
       "  'featured',\n",
       "  'features',\n",
       "  'featuring',\n",
       "  'feel',\n",
       "  'feeling',\n",
       "  'feelings',\n",
       "  'feels',\n",
       "  'feet',\n",
       "  'fell',\n",
       "  'fellow',\n",
       "  'felt',\n",
       "  'female',\n",
       "  'festival',\n",
       "  'few',\n",
       "  'fiction',\n",
       "  'fictional',\n",
       "  'field',\n",
       "  'fight',\n",
       "  'fighting',\n",
       "  'fights',\n",
       "  'figure',\n",
       "  'figured',\n",
       "  ...])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ww_ppmi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('superb', 1.1102230246251565e-16),\n",
       " ('excellent', 0.17869471726861819),\n",
       " ('brilliant', 0.17957541847117064),\n",
       " ('highly', 0.1832815805653859),\n",
       " ('direction', 0.18624109155299962)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neighbors(word='superb', mat=ww_ppmi[0], rownames=ww_ppmi[1], distfunc=cosine)[: 5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 1:\n",
    "\n",
    "First complete all parts in the notebook you haven't completed yet. Go through the rest of the notebook. At the end of the notebook there are a few questions to complete. Please write your answers to the 4 questions in NYU classes when you submit the assignment. Note you have to submit the notebook as well due to PMI being graded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimensionality reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above methods deliver solid results. However, they are not capable of capturing higher-order associations in the data. For example, both _gnarly_ and _wicked_ are used as slangily positive adjectives. We thus expect them to have many of the same neighbors. However, at least stereotypically, _gnarly_ is Californian and _wicked_ is Bostonian. Thus, they are unlikely \n",
    "to occur often in the same texts. Dimensionality reduction techniques are often capable of capturing their semantic similarity (and have the added advantage of shrinking the size of our data structures).\n",
    "\n",
    "The general goal of dimensionality reduction is to eliminate rows/columns that are highly correlated while bringing similar things together and pushing dissimilar things apart. __Latent Semantic Analysis__ (LSA) is a prominent method. It is an application of truncated __singular value decomposition__ (SVD). SVD is a central matrix operation; 'truncation' here means looking only at submatrices of the full decomposition. LSA seeks not only to find a reduced-sized matrix but also to capture similarities that come not just from direct co-occurrence, but also from second-order co-occurrence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lsa(mat=None, rownames=None, k=100):\n",
    "    \"\"\"Latent Semantic Analysis using pure scipy.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    mat : 2d np.array\n",
    "       The matrix to operate on.\n",
    "           \n",
    "    rownames : list of str or None\n",
    "        Not used; it's an argument only for consistency with other methods \n",
    "        defined here.\n",
    "        \n",
    "    k : int (default: 100)\n",
    "        Number of dimensions to truncate to.\n",
    "        \n",
    "    Returns\n",
    "    -------    \n",
    "    (np.array, list of str)\n",
    "        The first member is the SVD-reduced version of `mat` with \n",
    "        dimension (m x k), where m is the rowcount of mat and `k` is \n",
    "        either the user-supplied k or the column count of `mat`, whichever \n",
    "        is smaller. The second member is `rownames` (unchanged).\n",
    "\n",
    "    \"\"\"    \n",
    "    rowmat, singvals, colmat = svd(mat, full_matrices=False)\n",
    "    singvals = np.diag(singvals)\n",
    "    trunc = np.dot(rowmat[:, 0:k], singvals[0:k, 0:k])\n",
    "    return (trunc, rownames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a look at the example from the slides:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnmat = np.array([\n",
    "    [1,0,1,0,0,0],\n",
    "    [0,1,0,1,0,0],\n",
    "    [1,1,1,1,0,0],\n",
    "    [0,0,0,0,1,1],\n",
    "    [0,0,0,0,0,1]], dtype='float64')\n",
    "gn_rownames = ['gnarly', 'wicked', 'awesome', 'lame', 'terrible']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('gnarly', 2.2204460492503131e-16),\n",
       " ('awesome', 0.29289321881345254),\n",
       " ('wicked', 1.0),\n",
       " ('lame', 1.0),\n",
       " ('terrible', 1.0)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neighbors(word='gnarly', mat=gnmat, rownames=gn_rownames, distfunc=cosine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that _gnarly_ and _wicked_ are not close to each other. (Well, it's a small space, but they are as close as _gnarly_ and _lame_.) Reweighting by PMI, PPMI, or TF-IDF is no help. LSA to the rescue:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnmat_lsa = lsa(mat=gnmat, rownames=gn_rownames, k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('gnarly', 0.0),\n",
       " ('wicked', 0.0),\n",
       " ('awesome', 0.0),\n",
       " ('lame', 1.0),\n",
       " ('terrible', 1.0)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neighbors(word='gnarly', mat=gnmat_lsa[0], rownames=gnmat_lsa[1], distfunc=cosine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word analogies evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word analogies provide another kind of evaluation for distributed representations. Here, we are given three vectors A, B, and C, in the relationship\n",
    "\n",
    "_A is to B as C is to __ _\n",
    "\n",
    "and asked to identify the fourth that completes the analogy. This section conducts such analyses using a large, automatically collected analogies datset from Google. These analogies are by and large substantially easier than the classic brain-teaser analogies that used to appear on tests like the SAT, but it's still an interesting, demanding\n",
    "task. \n",
    "\n",
    "The core idea idea is that we make predictions by creating the vector\n",
    "\n",
    "$$(A - B) + C$$ \n",
    "\n",
    "and then ranking all vectors based on their distance from this new vector, choosing the closest as our prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analogy_completion(a, b, c, mat, rownames, distfunc=cosine):\n",
    "    \"\"\"a is to be as c is to predicted, where predicted is the \n",
    "    closest to (b-a) + c\"\"\"\n",
    "    for x in (a, b, c):\n",
    "        if x not in rownames:\n",
    "            raise ValueError('%s is not in this VSM' % x)\n",
    "    avec = mat[rownames.index(a)]\n",
    "    bvec = mat[rownames.index(b)]\n",
    "    cvec = mat[rownames.index(c)]\n",
    "    newvec = (bvec - avec) + cvec\n",
    "    dists = [(w, distfunc(newvec, mat[i])) for i, w in enumerate(rownames) if w not in (a, b, c)]\n",
    "    return sorted(dists, key=itemgetter(1), reverse=False)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('musicals', 0.81649739757410089),\n",
       " ('warner', 0.86584175374213679),\n",
       " ('singing', 0.8714641985035424),\n",
       " ('sounded', 0.87893875701575408),\n",
       " ('ball', 0.88854680186275437)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analogy_completion('dance', 'dancing', 'sing', \n",
    "    mat=ww_ppmi[0], rownames=ww_ppmi[1])[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analogy_evaluation(\n",
    "        mat, \n",
    "        rownames, \n",
    "        src_filename='gram1-adjective-to-adverb.txt', \n",
    "        distfunc=cosine):\n",
    "    \"\"\"Basic analogies evaluation for a file `src_filename `\n",
    "    in `question-data/`.\n",
    "    \n",
    "    Parameters\n",
    "    ----------    \n",
    "    mat : 2d np.array\n",
    "        The VSM being evaluated.\n",
    "        \n",
    "    rownames : list of str\n",
    "        The names of the rows in `mat`.\n",
    "        \n",
    "    src_filename : str\n",
    "        Basename of the file to be evaluated. It's assumed to be in\n",
    "        `vsmdata_home`/question-data.\n",
    "        \n",
    "    distfunc : function mapping vector pairs to floats (default: `cosine`)\n",
    "        The measure of distance between vectors. Can also be `euclidean`, \n",
    "        `matching`, `jaccard`, as well as any other distance measure \n",
    "        between 1d vectors.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    (float, float)\n",
    "        The first is the mean reciprocal rank of the predictions and \n",
    "        the second is the accuracy of the predictions.\n",
    "    \n",
    "    \"\"\"\n",
    "    src_filename = os.path.join(vsmdata_home, 'question-data', src_filename)\n",
    "    # Read in the data and restrict to problems we can solve:\n",
    "    data = [line.split() for line in open(src_filename).read().splitlines()]\n",
    "    data = [prob for prob in data if set(prob) <= set(rownames)]\n",
    "    # Run the evaluation, collecting accuracy and rankings:\n",
    "    results = defaultdict(int)\n",
    "    ranks = []\n",
    "    for a, b, c, d in data:\n",
    "        predicted = analogy_completion(a, b, c, mat=mat, rownames=rownames, distfunc=distfunc)\n",
    "        # print \"%s is to %s as %s is to %s (actual is %s)\" % (a, b, c, predicted, d)\n",
    "        results[predicted[0][0] == d] += 1\n",
    "        predicted_words, _ = zip(*predicted)\n",
    "        ranks.append(predicted_words.index(d))\n",
    "    # Return the mean reciprocal rank and the accuracy results:\n",
    "    mrr = np.mean(1.0/(np.array(ranks)+1))\n",
    "    return (mrr, results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some example evaluations, again using our baseline `ww_pmi` VSM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.043182134085512081, defaultdict(int, {False: 177, True: 5}))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analogy_evaluation(mat=ww_ppmi[0], rownames=ww_ppmi[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.092877996458544068, defaultdict(int, {False: 228, True: 12}))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analogy_evaluation(src_filename=\"gram7-past-tense.txt\", mat=ww_ppmi[0], rownames=ww_ppmi[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework Questions [10 points (8 below + 2pts for PMI)]\n",
    "\n",
    "Please submit the answers to these questions on NYU classes and not on the notebook. You will submit the notebook as well because we are grading the PMI part."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. PMI patterns [2 points]\n",
    "\n",
    "Consider the matrix `np.array([[1.0, 0.0, 0.0], [1000.0, 1000.0, 4000.0], [1000.0, 2000.0, 999.0]])`. Reweight this matrix using `pmi` with `positive=True`. __Submit__: (i) the value obtained for cell `[0,0]`, and (ii) a 1&ndash;2 sentence explanation of what is what is likely problematic about this value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = np.array([[1.0, 0.0, 0.0], [1000.0, 1000.0, 4000.0], [1000.0, 2000.0, 999.0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppmi = pmi(mat=matrix, positive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 8.51669332,  0.10536052,  0.        ])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ppmi[0][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output ppmi matrix has 0 value, because the input matrix has 0 word counts. Just because an event has never been observed in training data does not mean it cannot occur in test data (data sparsity issue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Dealing with the problematic value [2 points]\n",
    "\n",
    "Give a suggestion for dealing with the problematic value (0.5pts) and explain why it deals with this (1pt). Show this empirically (0.5pt)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use Laplace smoothing to deal with the above problem. It raises the baseline above 0. Before computing PMI, a small constant k (values of 0.1-3 are common) is added to each of the counts, shrinking\n",
    "(discounting) all the non-zero values. The larger the k, the more the non-zero counts are discounted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Distances  [2 points]\n",
    "\n",
    "In a few sentences, describe the major difference between Euclidean and Cosine distance and what that affects.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Euclidean is length of the most direct line between the two points. Cosine distance takes overall length into account. The similarity part of this (the righthand term of the subtraction) is actually measuring the _angles_ between the two vectors. `\n",
    "\n",
    "Cosine similarity is generally used as a metric for measuring distance when the magnitude of the vectors does not matter. This happens for example when working with text data represented by word counts. We could assume that when a word (e.g. science) occurs more frequent in document 1 than it does in document 2, that document 1 is more related to the topic of science. However, it could also be the case that we are working with documents of uneven lengths (Wikipedia articles for example). Then, science probably occurred more in document 1 just because it was way longer than document 2. Cosine similarity corrects for this.\n",
    "\n",
    "When classifying documents we'd like to categorize them by their overall sentiment, so we use the angular distance.\n",
    "\n",
    "Euclidean distance is susceptible to documents being clustered by their L2-norm (magnitude, in the 2 dimensional case) instead of direction. I.e. vectors with quite different directions would be clustered because their distances from origin are similar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. PPMI [1 point for each]\n",
    "\n",
    "A. We start with a word-word cooccurence matrix and applied PMI to this. Which of the following describe the resulting vectors (choose 2): Sparse, Dense, Long, Short\n",
    "\n",
    "\n",
    "B. If you wanted the opposite style of representation, what method would you use?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Long Sparse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Short, Dense - we will use LSA - SVD"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
